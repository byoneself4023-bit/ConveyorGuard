"""
ConveyorGuard - Streamlit Demo
ì´ì†¡ì¥ì¹˜ ì—´í™” ì˜ˆì¸¡ AI ì‹œìŠ¤í…œ ë°ëª¨ (ì—°êµ¬ ìŠ¤í† ë¦¬ ì¤‘ì‹¬)
"""

import os
import json
import asyncio
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from dotenv import load_dotenv

# --- í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ---
env_paths = [
    Path(__file__).parent.parent / "conveyorguard-api" / ".env",
    Path(__file__).parent.parent / "llm-service" / ".env",
    Path(__file__).parent.parent / ".env",
]
for p in env_paths:
    if p.exists():
        load_dotenv(p)

# --- Supabase ì—°ê²° ---
from supabase import create_client

@st.cache_resource
def get_supabase():
    # Streamlit Cloud: st.secrets ìš°ì„ , ë¡œì»¬: í™˜ê²½ë³€ìˆ˜ fallback
    url = st.secrets.get("SUPABASE_URL", os.environ.get("SUPABASE_URL", ""))
    key = st.secrets.get("SUPABASE_KEY", os.environ.get("SUPABASE_KEY", ""))
    if not url or not key:
        st.error("SUPABASE_URL / SUPABASE_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”. (Streamlit Cloud: Secrets ë©”ë‰´ / ë¡œì»¬: .env íŒŒì¼)")
        st.stop()
    return create_client(url, key)

# --- ìƒìˆ˜ ---
STATE_LABELS = {0: "ì •ìƒ", 1: "ê²½ë¯¸", 2: "ì¤‘ê°„", 3: "ì‹¬ê°"}
STATE_COLORS = {0: "#22C55E", 1: "#FACC15", 2: "#F97316", 3: "#EF4444"}
STATE_ICONS = {0: "ğŸŸ¢", 1: "ğŸŸ¡", 2: "ğŸŸ ", 3: "ğŸ”´"}
PROJECT_ROOT = Path(__file__).parent.parent

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ConveyorGuard",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="collapsed",
)

st.markdown("""
<style>
    .block-container { padding-top: 1rem; }
    div[data-testid="stMetric"] {
        background: rgba(30, 41, 59, 0.8);
        border: 1px solid rgba(59, 130, 246, 0.3);
        border-radius: 8px;
        padding: 12px 16px;
    }
    div[data-testid="stMetric"] label { font-size: 0.85rem; }
    .sensor-gauge { margin-bottom: 4px; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ­ ConveyorGuard")
st.caption("ì´ì†¡ì¥ì¹˜ ì—´í™” ì˜ˆì¸¡ AI ì‹œìŠ¤í…œ")

# ============================================================
# 3íƒ­ êµ¬ì„± (ì—°êµ¬ ìŠ¤í† ë¦¬ ì¤‘ì‹¬)
# ============================================================
tab1, tab2, tab3 = st.tabs([
    "ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”",
    "ğŸ”¬ ì‹¤í—˜ ì—¬ì •",
    "ğŸ­ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§",
])


# ============================================================
# íƒ­ 1: í”„ë¡œì íŠ¸ ê°œìš”
# ============================================================
with tab1:
    st.subheader("ë°˜ë„ì²´ ì´ì†¡ì¥ì¹˜ ì—´í™” ì˜ˆì¸¡ AI ì‹œìŠ¤í…œ")

    st.markdown("""
ë°˜ë„ì²´ ì œì¡°ë¼ì¸ì˜ ì»¨ë² ì´ì–´ ì´ì†¡ì¥ì¹˜ì—ì„œ ìˆ˜ì§‘ë˜ëŠ” **ì„¼ì„œ + ì—´í™”ìƒ ì´ë¯¸ì§€**ë¥¼ ë¶„ì„í•˜ì—¬,
ì—´í™” ìƒíƒœë¥¼ **4ë‹¨ê³„**(ì •ìƒ / ê²½ë¯¸ / ì¤‘ê°„ / ì‹¬ê°)ë¡œ **ì‚¬ì „ ì˜ˆì¸¡**í•©ë‹ˆë‹¤.
ë¹„ê³„íš ì •ì§€ë¥¼ ë°©ì§€í•˜ëŠ” **ì˜ˆì§€ë³´ì „(Predictive Maintenance)** ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
""")

    # í•µì‹¬ ìˆ˜ì¹˜ ë©”íŠ¸ë¦­
    ds_col1, ds_col2, ds_col3, ds_col4 = st.columns(4)
    ds_col1.metric("ì´ í”„ë ˆì„", "111,870")
    ds_col2.metric("ì„¸ì…˜", "341ê°œ")
    ds_col3.metric("ì„¼ì„œ", "8ì±„ë„")
    ds_col4.metric("ë¶ˆê· í˜• ë¹„ìœ¨", "6.34 : 1")

    st.divider()

    # í´ë˜ìŠ¤ ë¶„í¬ + ë°ì´í„° íŠ¹ì§•
    chart_col, info_col = st.columns([1, 1])

    with chart_col:
        st.markdown("#### í´ë˜ìŠ¤ ë¶„í¬")
        class_df = pd.DataFrame({
            "í´ë˜ìŠ¤": ["ì •ìƒ(0)", "ê²½ë¯¸(1)", "ì¤‘ê°„(2)", "ì‹¬ê°(3)"],
            "í”„ë ˆì„ ìˆ˜": [54928, 24081, 24191, 8670],
            "ë¹„ìœ¨": [49.1, 21.5, 21.6, 7.8],
        })
        fig = px.pie(class_df, names="í´ë˜ìŠ¤", values="í”„ë ˆì„ ìˆ˜",
                     color_discrete_sequence=["#22C55E", "#FACC15", "#F97316", "#EF4444"])
        fig.update_layout(height=350, margin=dict(l=0, r=0, t=30, b=0),
                          paper_bgcolor="rgba(0,0,0,0)")
        st.plotly_chart(fig, use_container_width=True)

    with info_col:
        st.markdown("#### ë©€í‹°ëª¨ë‹¬ ì…ë ¥")
        st.markdown("""
| ëª¨ë‹¬ë¦¬í‹° | ë‚´ìš© |
|----------|------|
| **ì„¼ì„œ** | NTC(ì˜¨ë„), PM1.0/2.5/10(ë¯¸ì„¸ë¨¼ì§€), CT1~4(ì „ë¥˜) |
| **ì—´í™”ìƒ** | 60x80 í•´ìƒë„, 30í”„ë ˆì„ ì‹œê³„ì—´ |
| **ì™¸ë¶€í™˜ê²½** | ì˜¨ë„, ìŠµë„, ì¡°ë„ |
""")
        st.markdown("""
- 30í”„ë ˆì„ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° êµ¬ì¡°
- ì„¸ì…˜ ê¸°ë°˜ Train/Val/Test ë¶„í•  (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)
""")

    st.divider()

    # ì—°êµ¬ íë¦„ë„ â€” í•µì‹¬ ì„œì‚¬ ì¤‘ì‹¬
    st.subheader("ì—°êµ¬ íë¦„")

    st.markdown("""
```
ë°ì´í„° íƒìƒ‰ â†’ ì „ì²˜ë¦¬ â†’ DL Baseline â†’ ML ë¹„êµ â†’ DL íŠœë‹ â†’ LLM ë¹„êµ â†’ ì•™ìƒë¸” â†’ ìµœì¢… ê²°ë¡ 
                         (93.24%)     (96.89%)                           (96.89%)
```
""")

    st.success("""ğŸ’¡ **í•µì‹¬ ì„œì‚¬**:
DLë¡œ ì‹œì‘ â†’ **MLì´ ë” ì¢‹ìŒ(ë°˜ì „)** â†’ DL íŠœë‹í•´ë„ ì—­ì „ ë¶ˆê°€ â†’ LLMìœ¼ë¡œ í•´ì„ë ¥ ë³´ì™„ â†’ ì•™ìƒë¸”ë„ ì†Œìš©ì—†ìŒ
â†’ **ìµœì¢…: LightGBM(ì •í™•ë„) + CNN(ë©€í‹°ëª¨ë‹¬) + Gemini(í•´ì„)**""")


# ============================================================
# íƒ­ 2: ì‹¤í—˜ ì—¬ì •
# ============================================================
with tab2:
    st.subheader("ì—°êµ¬ ìŠ¤í† ë¦¬")

    steps = [
        "00 ë°ì´í„° íƒìƒ‰",
        "01 ì „ì²˜ë¦¬",
        "02 DL Baseline",
        "03 ML ë¹„êµ",
        "04 DL íŠœë‹",
        "05 LLM ë¹„êµ",
        "06 ì•™ìƒë¸”",
        "07 ìµœì¢… ê²°ë¡ ",
    ]
    step = st.radio("ì‹¤í—˜ ë‹¨ê³„", steps, horizontal=True, key="exp_step")
    step_idx = steps.index(step)

    st.divider()

    # --- Step 00: ë°ì´í„° íƒìƒ‰ ---
    if step_idx == 0:
        st.markdown("### 00. ë°ì´í„° íƒìƒ‰ (EDA)")
        st.markdown("111,870 í”„ë ˆì„ì˜ ë©€í‹°ëª¨ë‹¬ ì„¼ì„œ ë°ì´í„° êµ¬ì¡°ì™€ ì´ìƒ íŒ¨í„´ì„ íŒŒì•…í•©ë‹ˆë‹¤.")

        c1, c2 = st.columns(2)
        with c1:
            # í´ë˜ìŠ¤ë³„ ì£¼ìš” ì„¼ì„œ í‰ê· ê°’ ë¹„êµ (ë…¸íŠ¸ë¶ 00ì—ì„œ ì¶”ì¶œ)
            import plotly.graph_objects as go
            sensor_labels = ["NTC", "CT1", "CT2", "PM2.5"]
            class_labels = ["ì •ìƒ", "ê²½ë¯¸", "ì¤‘ê°„", "ì‹¬ê°"]
            # ë…¸íŠ¸ë¶ 00 í´ë˜ìŠ¤ë³„ ì„¼ì„œ í‰ê· ê°’
            means = {
                "NTC":   [32.5, 38.2, 48.1, 72.6],
                "CT1":   [25.3, 35.8, 62.4, 138.5],
                "CT2":   [22.1, 30.5, 55.2, 98.3],
                "PM2.5": [18.0, 42.5, 128.0, 285.0],
            }
            colors = ["#22C55E", "#FACC15", "#F97316", "#EF4444"]
            fig = go.Figure()
            for i, cls in enumerate(class_labels):
                fig.add_trace(go.Bar(
                    name=cls, x=sensor_labels,
                    y=[means[s][i] for s in sensor_labels],
                    marker_color=colors[i],
                ))
            fig.update_layout(
                barmode="group", title="í´ë˜ìŠ¤ë³„ ì„¼ì„œ í‰ê· ê°’",
                height=300, margin=dict(l=0, r=0, t=30, b=0),
                paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                legend=dict(orientation="h", y=-0.15),
            )
            st.plotly_chart(fig, use_container_width=True)

        with c2:
            # ì„¼ì„œ ìƒê´€ íˆíŠ¸ë§µ
            sensor_names = ["NTC", "PM1.0", "PM2.5", "PM10", "CT1", "CT2", "CT3", "CT4"]
            corr_matrix = np.array([
                [1.00, 0.12, 0.15, 0.13, 0.45, 0.42, 0.38, 0.40],
                [0.12, 1.00, 0.95, 0.92, 0.08, 0.07, 0.06, 0.07],
                [0.15, 0.95, 1.00, 0.97, 0.10, 0.09, 0.08, 0.09],
                [0.13, 0.92, 0.97, 1.00, 0.09, 0.08, 0.07, 0.08],
                [0.45, 0.08, 0.10, 0.09, 1.00, 0.88, 0.85, 0.87],
                [0.42, 0.07, 0.09, 0.08, 0.88, 1.00, 0.90, 0.91],
                [0.38, 0.06, 0.08, 0.07, 0.85, 0.90, 1.00, 0.93],
                [0.40, 0.07, 0.09, 0.08, 0.87, 0.91, 0.93, 1.00],
            ])
            fig = px.imshow(corr_matrix, x=sensor_names, y=sensor_names,
                            color_continuous_scale="RdBu_r", zmin=-1, zmax=1,
                            title="ì„¼ì„œ ê°„ ìƒê´€ê´€ê³„")
            fig.update_layout(height=300, margin=dict(l=0, r=0, t=30, b=0),
                              paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig, use_container_width=True)

        st.info("ğŸ’¡ **ë°œê²¬**: ì‹¬ê° í´ë˜ìŠ¤ì—ì„œ NTC, CT1, PM2.5 í‰ê· ì´ ê¸‰ë“±. PM ì„¼ì„œë¼ë¦¬(0.95), CT ì„¼ì„œë¼ë¦¬(0.90) ë†’ì€ ìƒê´€ â†’ ë‹¤ì¤‘ê³µì„ ì„± ì£¼ì˜ í•„ìš”.")

        # ì‹¬í™”: ì„¼ì„œ ì¤‘ìš”ë„ ìˆœìœ„
        st.markdown("#### ì„¼ì„œë³„ ì—´í™” ìƒíƒœ ìƒê´€ë„")
        st.markdown("""
| ìˆœìœ„ | ì„¼ì„œ | ìƒê´€ë„ | ì˜ë¯¸ |
|------|------|--------|------|
| 1 | **NTC (ì˜¨ë„)** | **0.79** | ì—´í™” ìƒíƒœì™€ ê°€ì¥ ê°•í•œ ìƒê´€ |
| 2 | CT2 (ì „ë¥˜) | 0.38 | ëª¨í„° ë¶€í•˜ ë°˜ì˜ |
| 3 | CT1 (ì „ë¥˜) | 0.34 | ì „ë¥˜ ì´ìƒ íŒ¨í„´ |
| 4 | PM2.5 | 0.15 | ë¯¸ì„¸ë¨¼ì§€ ì¦ê°€ |

> **ì‹¬ê°(3) í´ë˜ìŠ¤ íŠ¹ì„±**: ì„¸ì…˜ ì „ì²´ê°€ ì‹¬ê°ì¸ ê²½ìš° 0ê°œ, í•˜ì§€ë§Œ ì‹¬ê° í¬í•¨ ì„¸ì…˜ì€ 289ê°œ(85%)
> â†’ ì„¸ì…˜ ë‹¨ìœ„ê°€ ì•„ë‹Œ **ìœˆë„ìš° ë‹¨ìœ„ ë¶„ë¥˜**ê°€ í•„ìˆ˜
""")

    # --- Step 01: ì „ì²˜ë¦¬ ---
    elif step_idx == 1:
        st.markdown("### 01. ì „ì²˜ë¦¬")
        st.markdown("ì‹œê³„ì—´ ì„¼ì„œ ë°ì´í„°ë¥¼ ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

        st.markdown("""
#### 30í”„ë ˆì„ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° êµ¬ì¡°
```
ì„¸ì…˜ ë‚´ í”„ë ˆì„:  [f1] [f2] [f3] ... [f30] [f31] [f32] ...
                 |__________________________|
                          ìœˆë„ìš° 1
                      |__________________________|
                               ìœˆë„ìš° 2
```
""")

        w_col1, w_col2, w_col3 = st.columns(3)
        w_col1.metric("ìœˆë„ìš° í¬ê¸°", "30 í”„ë ˆì„")
        w_col2.metric("ì„¸ì…˜ ìˆ˜", "341ê°œ")
        w_col3.metric("ë¶„í•  ë°©ì‹", "ì„¸ì…˜ ê¸°ë°˜")

        st.markdown("""
| í•­ëª© | ì„¤ëª… |
|------|------|
| ìœˆë„ìš° | 30í”„ë ˆì„ ìŠ¬ë¼ì´ë”©, stride=1 |
| ë¶„í•  | ì„¸ì…˜ ë‹¨ìœ„ Train(70%) / Val(15%) / Test(15%) |
| ì…ë ¥ ëª¨ë‹¬ë¦¬í‹° | ì„¼ì„œ(8ch) + ì—´í™”ìƒ(224x224) + ì™¸ë¶€í™˜ê²½(ì˜¨ë„/ìŠµë„) |
""")

        st.info("ğŸ’¡ **ë°œê²¬**: ì„¸ì…˜ ê¸°ë°˜ ë¶„í• ë¡œ ë°ì´í„° ëˆ„ì¶œ(data leakage) ë°©ì§€. ê°™ì€ ì„¸ì…˜ì˜ í”„ë ˆì„ì´ Trainê³¼ Testì— ë™ì‹œì— í¬í•¨ë˜ì§€ ì•Šë„ë¡ ë³´ì¥.")

    # --- Step 02: DL Baseline ---
    elif step_idx == 2:
        st.markdown("### 02. DL Baseline (CNN + Transformer)")
        st.markdown("3-modal ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ baselineìœ¼ë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.")

        st.markdown("""
#### ëª¨ë¸ ì•„í‚¤í…ì²˜
```
ì„¼ì„œ (8ch x 30)  â”€â†’ [1D-CNN + Transformer] â”€â”
ì—´í™”ìƒ (224x224) â”€â†’ [ResNet-18 backbone]     â”œâ†’ [Fusion + MLP] â†’ 4-class
ì™¸ë¶€í™˜ê²½ (2ch)   â”€â†’ [Linear]                 â”˜
```
""")

        perf_col1, perf_col2, perf_col3 = st.columns(3)
        perf_col1.metric("Test Accuracy", "93.24%")
        perf_col2.metric("Test F1 Score", "93.09%")
        perf_col3.metric("ëª¨ë¸ í¬ê¸°", "13.5 MB")

        # ì‹¬í™”: í•™ìŠµ ê³¡ì„  + Confusion Matrix
        detail_col1, detail_col2 = st.columns(2)
        with detail_col1:
            st.markdown("#### í•™ìŠµ ê³¡ì„ ")
            epoch_data = pd.DataFrame({
                "Epoch": [1, 2, 8, 14, 16, 19, 22, 23],
                "Val Acc (%)": [83.1, 88.5, 89.6, 90.5, 92.0, 92.7, 92.7, 93.2],
            })
            fig = px.line(epoch_data, x="Epoch", y="Val Acc (%)",
                          title="Validation Accuracy", markers=True)
            fig.update_layout(height=280, margin=dict(l=0, r=0, t=30, b=0),
                              paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig, use_container_width=True)

        with detail_col2:
            # Confusion Matrix (ë…¸íŠ¸ë¶ 02 ê²°ê³¼)
            st.markdown("#### Confusion Matrix (Test)")
            cm_labels = ["ì •ìƒ", "ê²½ë¯¸", "ì¤‘ê°„", "ì‹¬ê°"]
            cm_data = np.array([
                [666, 122, 0, 0],
                [20, 336, 15, 0],
                [3, 21, 324, 13],
                [1, 0, 2, 85],
            ])
            fig = px.imshow(cm_data, x=cm_labels, y=cm_labels,
                            color_continuous_scale="Blues", text_auto=True,
                            labels=dict(x="ì˜ˆì¸¡", y="ì‹¤ì œ", color="ê±´ìˆ˜"))
            fig.update_layout(height=280, margin=dict(l=0, r=0, t=30, b=0),
                              paper_bgcolor="rgba(0,0,0,0)")
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("""
| í´ë˜ìŠ¤ | Precision | Recall | F1 | ì£¼ìš” í˜¼ë™ |
|--------|-----------|--------|----|----------|
| ì •ìƒ(0) | 0.96 | 0.97 | 0.96 | |
| ê²½ë¯¸(1) | 0.88 | 0.87 | 0.88 | ì •ìƒâ†’ê²½ë¯¸ 122ê±´ (ê³¼íƒì§€) |
| ì¤‘ê°„(2) | 0.89 | 0.90 | 0.89 | |
| **ì‹¬ê°(3)** | **0.96** | **0.93** | **0.95** | ì‹¬ê°â†’ì¤‘ê°„ ë‹¨ 2ê±´ |
""")

        st.info("ğŸ’¡ **ë°œê²¬**: 3-modal ë”¥ëŸ¬ë‹ìœ¼ë¡œ 93.24% ë‹¬ì„±. ê´œì°®ì€ ì„±ëŠ¥ì´ì§€ë§Œ, ë‹¤ìŒ ë‹¨ê³„ì—ì„œ MLê³¼ ë¹„êµí•©ë‹ˆë‹¤.")

        with st.expander("í•µì‹¬ ì½”ë“œ: ConveyorGuardModel"):
            st.code("""class ConveyorGuardModel(nn.Module):
    \"\"\"3-modal fusion: Sensor + Thermal Image + External Environment\"\"\"
    def __init__(self, embed_dim=128, num_classes=4):
        super().__init__()
        self.sensor_encoder = SensorEncoder(input_dim=8, embed_dim=embed_dim)
        self.image_encoder = ImageEncoder(embed_dim=embed_dim)
        self.external_encoder = nn.Sequential(
            nn.Linear(3, embed_dim), nn.LayerNorm(embed_dim), nn.GELU()
        )
        self.sensor_temporal = TemporalEncoder(embed_dim=embed_dim)
        self.image_temporal = TemporalEncoder(embed_dim=embed_dim)
        self.fusion = CrossAttentionFusion(embed_dim=embed_dim)

        # FiLM: Feature-wise Linear Modulation
        self.film_gamma = nn.Linear(embed_dim, embed_dim)
        self.film_beta = nn.Linear(embed_dim, embed_dim)

        self.classifier = nn.Sequential(
            nn.Linear(embed_dim, embed_dim), nn.LayerNorm(embed_dim),
            nn.GELU(), nn.Dropout(0.2), nn.Linear(embed_dim, num_classes)
        )

    def forward(self, sensors, images, externals=None):
        sensor_feat = self.sensor_temporal(self.sensor_encoder(sensors))
        image_feat = self.image_temporal(self.image_encoder(images))
        fused = self.fusion(sensor_feat, image_feat)
        pooled = fused.mean(dim=1)

        if externals is not None:  # FiLM conditioning
            ext_feat = self.external_encoder(externals).mean(dim=1)
            pooled = self.film_gamma(ext_feat) * pooled + self.film_beta(ext_feat)

        return self.classifier(pooled)""", language="python")

    # --- Step 03: ML ë¹„êµ ---
    elif step_idx == 3:
        st.markdown("### 03. ML 8ì¢… ë¹„êµ")

        st.warning("âš¡ **ë°˜ì „!** ì „í†µ ML ëª¨ë¸ LightGBMì´ 96.89%ë¡œ ë”¥ëŸ¬ë‹(93.24%)ì„ ë›°ì–´ë„˜ì—ˆìŠµë‹ˆë‹¤!")

        ml_data = pd.DataFrame({
            "ëª¨ë¸": ["LightGBM", "XGBoost", "CatBoost", "RandomForest",
                    "DecisionTree", "KNN", "SVM", "Logistic"],
            "ì •í™•ë„": [96.89, 96.70, 96.46, 95.58, 92.97, 89.12, 87.75, 87.31],
        }).sort_values("ì •í™•ë„")

        fig = px.bar(ml_data, x="ì •í™•ë„", y="ëª¨ë¸", orientation="h",
                     title="ML 8ì¢… Test Accuracy (%)",
                     text=ml_data["ì •í™•ë„"].apply(lambda x: f"{x:.2f}%"))
        fig.update_layout(height=350, margin=dict(l=0, r=0, t=30, b=0),
                          paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                          xaxis_range=[85, 98])
        fig.update_traces(textposition="outside", marker_color="#3B82F6")
        fig.add_vline(x=93.24, line_dash="dash", line_color="#8B5CF6",
                      annotation_text="DL Baseline (93.24%)")
        st.plotly_chart(fig, use_container_width=True)

        comp_col1, comp_col2 = st.columns(2)
        with comp_col1:
            st.markdown("""
| | DL (CNN+Transformer) | ML (LightGBM) |
|---|---|---|
| **ì •í™•ë„** | 93.24% | **96.89%** |
| **í•™ìŠµ ì‹œê°„** | ~30ë¶„ | ~2.7ì´ˆ |
| **ì…ë ¥** | ì„¼ì„œ+ì—´í™”ìƒ+ì™¸ë¶€í™˜ê²½ | ì„¼ì„œ í”¼ì²˜ 64ê°œ |
""")
        with comp_col2:
            st.markdown("""
**ì™œ MLì´ ì´ê²¼ì„ê¹Œ?**
- ì •í˜• ì„¼ì„œ ë°ì´í„°ì—ì„œëŠ” íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì´ ìœ ë¦¬
- DLì€ ì´ë¯¸ì§€ ëª¨ë‹¬ë¦¬í‹°ì˜ ê¸°ì—¬ë„ê°€ ë‚®ì•„ ì˜¤ë²„í—¤ë“œë§Œ ì¶”ê°€
- LightGBMì€ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ëœ ì„¼ì„œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµ
""")

        st.info("ğŸ’¡ **ë°œê²¬**: ë©€í‹°ëª¨ë‹¬ DLë³´ë‹¤ ì„¼ì„œ í”¼ì²˜ë§Œ ì“°ëŠ” LightGBMì´ 3.65%p ë” ë†’ë‹¤. ì´ë¯¸ì§€ê°€ ì˜¤íˆë ¤ ë…¸ì´ì¦ˆ?")

        # ì‹¬í™”: Feature Importance + Confusion Matrix
        st.divider()
        deep_col1, deep_col2 = st.columns(2)

        with deep_col1:
            st.markdown("#### Feature Importance (Top 10)")
            fi_data = pd.DataFrame({
                "í”¼ì²˜": ["sensor_NTC_last", "sensor_CT2_diff", "sensor_CT2_std",
                         "sensor_NTC_max", "sensor_CT2_max", "sensor_CT2_mean",
                         "sensor_CT1_max", "sensor_CT1_diff", "sensor_PM10_min",
                         "sensor_PM10_std"],
                "Importance": [0.230, 0.085, 0.067, 0.057, 0.045, 0.042,
                               0.041, 0.035, 0.035, 0.030],
            })
            fig = px.bar(fi_data, x="Importance", y="í”¼ì²˜", orientation="h",
                         title="XGBoost Feature Importance")
            fig.update_layout(height=350, margin=dict(l=0, r=0, t=30, b=0),
                              paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                              yaxis=dict(autorange="reversed"))
            fig.update_traces(marker_color="#F97316")
            st.plotly_chart(fig, use_container_width=True)

        with deep_col2:
            st.markdown("#### Confusion Matrix (LightGBM)")
            cm = np.array([
                [781,  7,  0,  0],
                [  8,349, 14,  0],
                [  0, 17,342,  2],
                [  0,  0,  2, 86],
            ])
            fig = px.imshow(cm,
                            x=["ì •ìƒ", "ê²½ë¯¸", "ì¤‘ê°„", "ì‹¬ê°"],
                            y=["ì •ìƒ", "ê²½ë¯¸", "ì¤‘ê°„", "ì‹¬ê°"],
                            text_auto=True, color_continuous_scale="Blues",
                            title="Predicted vs Actual")
            fig.update_layout(height=350, margin=dict(l=0, r=0, t=30, b=0),
                              paper_bgcolor="rgba(0,0,0,0)",
                              xaxis_title="Predicted", yaxis_title="Actual")
            st.plotly_chart(fig, use_container_width=True)

        # EDA ê²€ì¦
        st.markdown("#### EDA ì¸ì‚¬ì´íŠ¸ â†’ ëª¨ë¸ ê²€ì¦")
        st.markdown("""
| EDA ìƒê´€ë„ | Feature Importance | ì¼ì¹˜ ì—¬ë¶€ |
|------------|-------------------|-----------|
| NTC 0.79 (1ìœ„) | NTC_last 0.23 (1ìœ„) | âœ… |
| CT2 0.38 (2ìœ„) | CT2_diff 0.09 (2ìœ„) | âœ… |
| CT1 0.34 (3ìœ„) | CT1_max, CT1_diff (ìƒìœ„) | âœ… |

> EDAì—ì„œ ë°œê²¬í•œ ì„¼ì„œ ì¤‘ìš”ë„ê°€ ëª¨ë¸ì˜ Feature Importanceì—ì„œë„ ê·¸ëŒ€ë¡œ ê²€ì¦ë¨
""")

        with st.expander("í•µì‹¬ ì½”ë“œ: ë©€í‹°ëª¨ë‹¬ â†’ 64ê°œ í”¼ì²˜ ë³€í™˜"):
            st.code("""def extract_features(data: dict) -> np.ndarray:
    \"\"\"ë©€í‹°ëª¨ë‹¬ ì‹œê³„ì—´ â†’ 64ì°¨ì› í”¼ì²˜ ë²¡í„° ë³€í™˜
    Sensor (N,30,8) + Image (N,30,60,80) + External (N,30,3) â†’ (N,64)\"\"\"

    sensors = data['sensors']
    # ì„¼ì„œ: 6ì¢… í†µê³„ x 8ì±„ë„ = 48ê°œ í”¼ì²˜
    sensor_mean = sensors.mean(axis=1)
    sensor_std  = sensors.std(axis=1)
    sensor_max  = sensors.max(axis=1)
    sensor_min  = sensors.min(axis=1)
    sensor_last = sensors[:, -1, :]
    sensor_diff = sensors[:, -1, :] - sensors[:, 0, :]  # ì‹œê°„ ë³€í™”ëŸ‰

    # ì—´í™”ìƒ: ê³µê°„+ì‹œê°„ í†µê³„ = 7ê°œ í”¼ì²˜
    images = data['images']
    img_frame_mean = images.mean(axis=(2, 3))
    img_frame_max  = images.max(axis=(2, 3))
    img_mean  = img_frame_mean.mean(axis=1, keepdims=True)
    img_max   = img_frame_max.max(axis=1, keepdims=True)
    img_trend = img_frame_mean[:, -1:] - img_frame_mean[:, 0:1]  # ì—´ ë³€í™” ì¶”ì„¸

    # ì™¸ë¶€í™˜ê²½: 3ì¢… í†µê³„ x 3ì±„ë„ = 9ê°œ í”¼ì²˜
    external = data['external']
    ext_mean = external.mean(axis=1)
    ext_std  = external.std(axis=1)
    ext_last = external[:, -1, :]

    return np.concatenate([
        sensor_mean, sensor_std, sensor_max, sensor_min, sensor_last, sensor_diff,
        img_mean, img_max, img_trend,
        ext_mean, ext_std, ext_last
    ], axis=1)  # (N, 64)""", language="python")

    # --- Step 04: DL íŠœë‹ ---
    elif step_idx == 4:
        st.markdown("### 04. DL íŠœë‹ (Optuna + Ablation Study)")
        st.markdown("DL ì„±ëŠ¥ì„ ëŒì–´ì˜¬ë ¤ MLì„ ì—­ì „í•  ìˆ˜ ìˆì„ê¹Œ?")

        # Ablation Study
        ablation_df = pd.DataFrame({
            "êµ¬ì„±": ["Sensor Only", "Image Only", "Sensor+Image", "Full+FiLM"],
            "ì •í™•ë„": [89.12, 69.56, 89.64, 90.35],
        })
        fig = px.bar(ablation_df, x="êµ¬ì„±", y="ì •í™•ë„",
                     title="Ablation Study: ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„",
                     text=ablation_df["ì •í™•ë„"].apply(lambda x: f"{x:.2f}%"),
                     color="ì •í™•ë„",
                     color_continuous_scale=["#EF4444", "#FACC15", "#22C55E"])
        fig.update_layout(height=350, margin=dict(l=0, r=0, t=30, b=0),
                          paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                          yaxis_range=[60, 98], showlegend=False)
        fig.update_traces(textposition="outside")
        fig.add_hline(y=96.89, line_dash="dash", line_color="#3B82F6",
                      annotation_text="LightGBM (96.89%)")
        st.plotly_chart(fig, use_container_width=True)

        t_col1, t_col2 = st.columns(2)
        with t_col1:
            st.markdown("""
#### Optuna íƒìƒ‰ ê³µê°„ & ìµœì ê°’

| íŒŒë¼ë¯¸í„° | ë²”ìœ„ | ìµœì ê°’ |
|----------|------|--------|
| embed_dim | [128, 256] | **256** |
| num_heads | [4, 8] | **4** |
| num_layers | [1, 2] | **2** |
| dropout | [0.1, 0.3] | **0.1** |
| lr | 1e-4 ~ 1e-3 | **1.96e-4** |
| weight_decay | 1e-5 ~ 1e-3 | **5.4e-5** |
""")
        with t_col2:
            st.markdown("""
#### Trial ê²°ê³¼

| Trial | Val Acc | ìƒíƒœ |
|-------|---------|------|
| 0 | 88.74% | ì™„ë£Œ |
| 1 | 89.83% | ì™„ë£Œ |
| **2** | **90.48%** | **Best** |
| 3 | 90.09% | ì™„ë£Œ |
| 4-7 | - | Pruned |

**Pruning íš¨ê³¼**: MedianPrunerë¡œ ë¹„íš¨ìœ¨ Trial ì¡°ê¸° ì¢…ë£Œ â†’ GPU ì‹œê°„ ì ˆì•½
""")

        st.warning("ğŸ’¡ **ë°œê²¬**: ì„¼ì„œê°€ ì§€ë°°ì (89%), ì´ë¯¸ì§€ ê¸°ì—¬ ë¯¸ë¯¸(+0.5%p). Optuna íŠœë‹ìœ¼ë¡œë„ LightGBM 96.89%ë¥¼ ì—­ì „ ë¶ˆê°€.")

        with st.expander("í•µì‹¬ ì½”ë“œ: Optuna objective (Multi-GPU + AMP)"):
            st.code("""def objective(trial):
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
    embed_dim = trial.suggest_categorical('embed_dim', [128, 256])
    num_heads = trial.suggest_categorical('num_heads', [4, 8])
    num_layers = trial.suggest_int('num_layers', 1, 2)
    dropout = trial.suggest_float('dropout', 0.1, 0.3, step=0.1)
    lr = trial.suggest_float('lr', 1e-4, 1e-3, log=True)

    # DataParallel (T4 x2) + AMP (Mixed Precision)
    model = ConveyorGuardModel(embed_dim=embed_dim, num_heads=num_heads,
                                num_layers=num_layers, dropout=dropout)
    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)
    model = model.to(device)
    scaler = GradScaler()

    best_acc = 0
    for epoch in range(FIXED_EPOCHS):
        train_epoch_optimized(model, train_loader, criterion, optimizer, device, scaler)
        val_loss, val_acc = evaluate_optimized(model, val_loader, criterion, device)

        trial.report(val_acc, epoch)  # Optuna pruning
        if trial.should_prune():
            raise optuna.TrialPruned()

        if val_acc > best_acc:
            best_acc = val_acc

    del model; gc.collect(); torch.cuda.empty_cache()
    return best_acc""", language="python")

    # --- Step 05: LLM ë¹„êµ ---
    elif step_idx == 5:
        st.markdown("### 05. LLM 3ì¢… ë¹„êµ + LangGraph ë©€í‹° ì—ì´ì „íŠ¸")
        st.markdown("ì •í™•ë„ì—ì„œ MLì— ë°€ë¦° í•œê³„ë¥¼ **í•´ì„ë ¥**ìœ¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.")

        llm_df = pd.DataFrame({
            "ëª¨ë¸": ["Gemini 2.5 Flash", "Gemma-3-4B", "Qwen2.5-3B"],
            "ì‘ë‹µì‹œê°„(s)": [7.9, 14.6, 8.1],
            "JSON ì¶œë ¥": ["ìš°ìˆ˜", "ë¶ˆì•ˆì •", "ë³´í†µ"],
            "ì§„ë‹¨ ì •í™•ë„": ["ì •í™•í•˜ê³  ê°„ê²°", "ì¥í™©í•˜ê³  ë¶€ì •í™•", "ê°„ê²°í•˜ì§€ë§Œ ë¶€ì •í™•"],
            "ê²°ê³¼": ["âœ… ì±„íƒ", "âŒ", "âŒ"],
        })
        st.dataframe(llm_df, use_container_width=True, hide_index=True)

        l_col1, l_col2 = st.columns(2)
        with l_col1:
            fig = px.bar(
                pd.DataFrame({
                    "ëª¨ë¸": ["Gemini 2.5 Flash", "Gemma-3-4B", "Qwen2.5-3B"],
                    "ì‘ë‹µì‹œê°„(s)": [7.9, 14.6, 8.1],
                }),
                x="ëª¨ë¸", y="ì‘ë‹µì‹œê°„(s)", title="LLM ì‘ë‹µ ì‹œê°„ ë¹„êµ",
                text="ì‘ë‹µì‹œê°„(s)",
                color="ëª¨ë¸",
                color_discrete_sequence=["#22C55E", "#EF4444", "#F97316"],
            )
            fig.update_layout(height=300, margin=dict(l=0, r=0, t=30, b=0),
                              paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                              showlegend=False)
            fig.update_traces(textposition="outside")
            st.plotly_chart(fig, use_container_width=True)

        with l_col2:
            st.markdown("#### T4 GPU ì œì•½ â†’ ëª¨ë¸ ì„ íƒ")
            st.markdown("""
| ëª¨ë¸ | VRAM | T4 16GB | ì„ íƒ |
|------|------|---------|------|
| Gemma-3-12B | ~24GB | âŒ OOM | - |
| Qwen2.5-7B | ~14GB | ë¹ ë“¯ | - |
| **Gemma-3-4B** | ~8GB | âœ… | GPU 0 |
| **Qwen2.5-3B** | ~6GB | âœ… | GPU 1 |

4B + 3B ì¡°í•© = T4 x2ì— ê°ê° ë°°ì¹˜ ê°€ëŠ¥í•œ ìµœëŒ€ í¬ê¸°
""")

        # ì‹¬ê° ì¼€ì´ìŠ¤ ì‹¤ì œ ì‘ë‹µ ë¹„êµ
        st.divider()
        st.markdown("#### ì‹¤ì œ ì§„ë‹¨ ì‘ë‹µ ë¹„êµ (ì‹¬ê° ì¼€ì´ìŠ¤)")
        st.markdown("ì…ë ¥: `NTC 0.3Â°C, CT1 0.0A, ì—´í™”ìƒ max 1.0Â°C` â†’ ì„¤ë¹„ ë¯¸ê°€ë™ ì¶”ì •")

        resp_col1, resp_col2, resp_col3 = st.columns(3)
        with resp_col1:
            st.markdown("**Gemini 2.5 Flash** âœ…")
            st.caption("ì¥ë¹„ ë¯¸ê°€ë™ ë˜ëŠ” ì „ì› ì´ìƒ ì¶”ì •. CT ì „ë¥˜ 0.0A ë° ë‚®ì€ ì˜¨ë„ê°€ ì§€í‘œ. ì „ì› ë° ì¥ë¹„ ì‘ë™ ìƒíƒœë¥¼ ì ê²€í•˜ê³  í•„ìš” ì‹œ ì „ì› ê³µê¸‰ ì¡°ì¹˜.")
        with resp_col2:
            st.markdown("**Gemma-3-4B** âŒ")
            st.caption("ì‘ë‹µ ì‹¤íŒ¨ (N/A)")
        with resp_col3:
            st.markdown("**Qwen2.5-3B** â–³")
            st.caption("ì¥ë¹„ ì˜¨ë„ ì œì–´ ë¶ˆëŸ‰, CT1 ê³¼ë¶€í•˜... (ë°˜ë³µ ë¬¸êµ¬, í’ˆì§ˆ ë‚®ìŒ)")

        st.info("ğŸ’¡ **ë°œê²¬**: Gemini 2.5 Flashê°€ ì†ë„/í’ˆì§ˆ/ì•ˆì •ì„± ëª¨ë‘ 1ìœ„. LLMì€ ì •í™•ë„ê°€ ì•„ë‹Œ **í•´ì„ë ¥** ë³´ì™„ ì—­í• .")

        # LangGraph ë©€í‹° ì—ì´ì „íŠ¸
        st.divider()
        st.markdown("#### LangGraph ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°")
        st.markdown("ë‹¨ìˆœ LLM í˜¸ì¶œì´ ì•„ë‹Œ, ì‹¤ì œ ìœ ì§€ë³´ìˆ˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ë°˜ì˜í•œ **ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**.")

        st.markdown("""
```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  START  â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
              v
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Analyzer   â”‚  â† ì„¼ì„œ ë°ì´í„° ì •ìƒ/ì´ìƒ ë¶„ì„
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              v
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Diagnoser   â”‚  â† ì´ìƒ ì›ì¸ ì¶”ì • (3ê°€ì§€ ì´ë‚´)
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              v
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Advisor    â”‚  â† ìœ ì§€ë³´ìˆ˜ ì¡°ì¹˜ ì¶”ì²œ
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              v
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Reviewer   â”‚  â† ì§„ë‹¨ í’ˆì§ˆ ê²€ì¦
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                 â”‚
   REVISE           APPROVE
     â”‚                 â”‚
     v                 v
  Diagnoser        Finalize
  (ì¬ì§„ë‹¨)         (ë¦¬í¬íŠ¸ ìƒì„±)
```
""")

        st.markdown("""
| ì—ì´ì „íŠ¸ | ì—­í•  | ì¶œë ¥ |
|----------|------|------|
| **Analyzer** | ì„¼ì„œ ë°ì´í„° ì •ìƒ/ì´ìƒ íŒì • | ê° ì„¼ì„œë³„ ë¶„ì„ |
| **Diagnoser** | ì´ìƒ ì›ì¸ ì¶”ì • (3ê°€ì§€ ì´ë‚´) | ì›ì¸ ëª©ë¡ |
| **Advisor** | ì¦‰ì‹œ/ì˜ˆë°©/ì ê²€ ì¡°ì¹˜ ì¶”ì²œ | ì¡°ì¹˜ ì‚¬í•­ |
| **Reviewer** | ì§„ë‹¨ í’ˆì§ˆ ê²€ì¦ â†’ APPROVE ë˜ëŠ” REVISE | í’ˆì§ˆ ê²Œì´íŠ¸ |

> **ì‹¤í–‰ ê²°ê³¼**: Reviewerê°€ 1íšŒ REVISE â†’ ìë™ ì¬ì§„ë‹¨ â†’ ìµœì¢… APPROVE (ì´ 91.5ì´ˆ)
""")

        with st.expander("í•µì‹¬ ì½”ë“œ: LangGraph StateGraph êµ¬ì„±"):
            st.code("""from langgraph.graph import StateGraph, END

class DiagnosisState(TypedDict):
    sensor_data: dict; thermal_data: dict
    analysis: str; diagnosis: str; advice: str
    review: str; review_count: int; final_report: str

def should_continue(state: DiagnosisState) -> str:
    \"\"\"Conditional routing: max 2 revisions\"\"\"
    if state['review_count'] >= 2:
        return 'end'
    if 'APPROVE' in state['review'].upper():
        return 'end'
    return 'revise'

# Build workflow graph
workflow = StateGraph(DiagnosisState)
workflow.add_node('analyzer', analyzer_node)
workflow.add_node('diagnoser', diagnoser_node)
workflow.add_node('advisor', advisor_node)
workflow.add_node('reviewer', reviewer_node)
workflow.add_node('finalize', finalize_node)

workflow.set_entry_point('analyzer')
workflow.add_edge('analyzer', 'diagnoser')
workflow.add_edge('diagnoser', 'advisor')
workflow.add_edge('advisor', 'reviewer')
workflow.add_conditional_edges('reviewer', should_continue,
    {'revise': 'diagnoser', 'end': 'finalize'})
workflow.add_edge('finalize', END)

app = workflow.compile()""", language="python")

    # --- Step 06: ì•™ìƒë¸” ---
    elif step_idx == 6:
        st.markdown("### 06. ì•™ìƒë¸” (Stacking)")
        st.markdown("ì—¬ëŸ¬ ëª¨ë¸ì„ ê²°í•©í•˜ë©´ LightGBMì„ ë›°ì–´ë„˜ì„ ìˆ˜ ìˆì„ê¹Œ?")

        # ì „ì²´ 9ì¢… ìˆœìœ„ í…Œì´ë¸”
        ens_all = pd.DataFrame({
            "ëª¨ë¸": ["LightGBM", "Stacking", "XGBoost", "Weighted Voting",
                     "Soft Voting", "CatBoost", "RandomForest", "Baseline CNN", "Tuned CNN"],
            "ìœ í˜•": ["ML", "Ensemble", "ML", "Ensemble",
                     "Ensemble", "ML", "ML", "DL", "DL"],
            "Test Acc (%)": [96.89, 96.89, 96.70, 96.70,
                            96.64, 96.46, 95.58, 92.72, 87.75],
        })
        fig = px.bar(ens_all.sort_values("Test Acc (%)"),
                     x="Test Acc (%)", y="ëª¨ë¸", color="ìœ í˜•", orientation="h",
                     title="ì•™ìƒë¸” í¬í•¨ ì „ì²´ ëª¨ë¸ ìˆœìœ„",
                     color_discrete_map={"ML": "#3B82F6", "DL": "#8B5CF6", "Ensemble": "#10B981"},
                     text=ens_all.sort_values("Test Acc (%)")["Test Acc (%)"].apply(lambda x: f"{x:.2f}%"))
        fig.update_layout(height=380, margin=dict(l=0, r=0, t=30, b=0),
                          paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                          xaxis_range=[85, 98])
        fig.update_traces(textposition="outside")
        st.plotly_chart(fig, use_container_width=True)

        st.markdown("""
| | LightGBM (ë‹¨ì¼) | Stacking Ensemble |
|---|---|---|
| **ì •í™•ë„** | 96.89% | 96.89% (ë™ë¥ ) |
| **ë³µì¡ë„** | ë‚®ìŒ (ë‹¨ì¼ ëª¨ë¸) | ë†’ìŒ (6ê°œ ëª¨ë¸ + ë©”íƒ€ëŸ¬ë„ˆ) |
| **ì¶”ë¡  ì‹œê°„** | ë¹ ë¦„ | ëŠë¦¼ |
| **ê²°ë¡ ** | **âœ… ë‹¨ì¼ ëª¨ë¸ì´ ìµœì ** | ì„±ëŠ¥ ì´ë“ ì—†ì´ ë³µì¡ë„ë§Œ ì¦ê°€ |
""")

        # Weighted Voting ê°€ì¤‘ì¹˜ ë¶„í¬
        st.markdown("#### Weighted Voting ê°€ì¤‘ì¹˜ ë¶„í¬")
        st.markdown("""
```
LightGBM:     0.1706  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
XGBoost:      0.1707  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CatBoost:     0.1699  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RandomForest: 0.1698  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Baseline CNN: 0.1640  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tuned CNN:    0.1550  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```
> ML 4ì¢…ì´ ê±°ì˜ ê· ë“±í•œ ê°€ì¤‘ì¹˜ â†’ DLì˜ ê¸°ì—¬ë„ê°€ ë‚®ì•„ ì•™ìƒë¸” íš¨ê³¼ ì œí•œì 
""")

        st.warning("ğŸ’¡ **ë°œê²¬**: Stacking ì•™ìƒë¸”ë„ 96.89%ë¡œ LightGBMê³¼ ë™ë¥ . ë³µì¡ë„ë§Œ ì¦ê°€í•˜ê³  ì„±ëŠ¥ ì´ë“ ì—†ìŒ â†’ ë‹¨ì¼ LightGBMì´ ìµœì .")

    # --- Step 07: ìµœì¢… ê²°ë¡  ---
    elif step_idx == 7:
        st.markdown("### 07. ìµœì¢… ê²°ë¡ : 13ê°œ ëª¨ë¸ ì¢…í•© ë¹„êµ")

        csv_path = PROJECT_ROOT / "data" / "results" / "final" / "final_comparison.csv"

        if csv_path.exists():
            df = pd.read_csv(csv_path)
            df = df.sort_values("Test_Acc", ascending=True).reset_index(drop=True)

            fig = px.bar(
                df,
                x="Test_Acc",
                y="Model",
                color="Type",
                orientation="h",
                title="13ê°œ ëª¨ë¸ Test Accuracy (%)",
                color_discrete_map={"ML": "#3B82F6", "DL": "#8B5CF6", "Ensemble": "#10B981"},
                text=df["Test_Acc"].apply(lambda x: f"{x:.2f}%"),
            )
            fig.update_layout(
                height=500,
                paper_bgcolor="rgba(0,0,0,0)",
                plot_bgcolor="rgba(0,0,0,0)",
                yaxis_title="",
                xaxis_title="Test Accuracy (%)",
                xaxis_range=[85, 98],
            )
            fig.update_traces(textposition="outside")
            st.plotly_chart(fig, use_container_width=True)

            display_df = df.sort_values("Test_Acc", ascending=False).reset_index(drop=True)
            display_df["Rank"] = range(1, len(display_df) + 1)
            table_df = display_df[["Rank", "Model", "Type", "Test_Acc", "Test_F1", "Train_Time"]].copy()
            table_df.columns = ["ìˆœìœ„", "ëª¨ë¸", "ìœ í˜•", "ì •í™•ë„ (%)", "F1 (%)", "í•™ìŠµì‹œê°„ (s)"]
            table_df["ì •í™•ë„ (%)"] = table_df["ì •í™•ë„ (%)"].apply(lambda x: f"{x:.2f}")
            table_df["F1 (%)"] = table_df["F1 (%)"].apply(lambda x: f"{x:.2f}")
            st.dataframe(table_df, use_container_width=True, hide_index=True)
        else:
            st.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

        st.divider()

        # ì„±ëŠ¥ í–¥ìƒ ìŠ¤í† ë¦¬ ë¼ì¸ ì°¨íŠ¸
        st.markdown("#### ì„±ëŠ¥ í–¥ìƒ ìŠ¤í† ë¦¬")
        import plotly.graph_objects as go

        story_data = pd.DataFrame({
            "ë‹¨ê³„": ["02: DL Baseline", "04: DL Tuned", "03: XGBoost", "06: Stacking"],
            "Acc": [93.24, 87.75, 96.70, 96.89],
            "ìƒ‰ìƒ": ["#F59E0B", "#F59E0B", "#3B82F6", "#EF4444"],
        })
        fig = go.Figure(go.Scatter(
            x=list(range(4)), y=story_data["Acc"],
            mode="lines+markers+text",
            text=[f"{m}<br>{a:.1f}%" for m, a in zip(story_data["ë‹¨ê³„"], story_data["Acc"])],
            textposition="top center",
            marker=dict(size=14, color=story_data["ìƒ‰ìƒ"].tolist()),
            line=dict(width=2, color="#6B7280"),
        ))
        fig.update_layout(
            height=350, margin=dict(l=0, r=0, t=10, b=0),
            paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
            xaxis=dict(tickvals=list(range(4)), ticktext=story_data["ë‹¨ê³„"].tolist()),
            yaxis_title="Test Accuracy (%)",
            yaxis=dict(range=[83, 100]),
        )
        st.plotly_chart(fig, use_container_width=True)

        # Accuracy vs Training Time ì‚°ì ë„ (ë…¸íŠ¸ë¶ 07)
        st.markdown("#### ì •í™•ë„ vs í•™ìŠµ ì‹œê°„")
        type_colors = {"ML": "#3B82F6", "DL": "#F59E0B", "Ensemble": "#10B981"}
        scatter_data = pd.DataFrame([
            {"Model": "LightGBM", "Type": "ML", "Acc": 96.89, "Time": 2.7},
            {"Model": "XGBoost", "Type": "ML", "Acc": 96.70, "Time": 3.8},
            {"Model": "CatBoost", "Type": "ML", "Acc": 96.46, "Time": 21.5},
            {"Model": "RandomForest", "Type": "ML", "Acc": 95.58, "Time": 3.7},
            {"Model": "DL Baseline", "Type": "DL", "Acc": 93.24, "Time": 2178},
            {"Model": "DL Tuned", "Type": "DL", "Acc": 87.75, "Time": 600},
            {"Model": "Stacking", "Type": "Ensemble", "Acc": 96.89, "Time": 10},
        ])
        fig = px.scatter(scatter_data, x="Time", y="Acc", color="Type",
                         text="Model", log_x=True, size_max=14,
                         color_discrete_map=type_colors,
                         labels={"Time": "í•™ìŠµ ì‹œê°„ (ì´ˆ, log)", "Acc": "Test Accuracy (%)"})
        fig.update_traces(textposition="top center", marker=dict(size=12))
        fig.update_layout(
            height=350, margin=dict(l=0, r=0, t=10, b=0),
            paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
            yaxis=dict(range=[85, 98]),
            legend=dict(orientation="h", y=-0.15),
        )
        st.plotly_chart(fig, use_container_width=True)

        # ë ˆì´ë” ì°¨íŠ¸ â€” Top 3 ëª¨ë¸ ë‹¤ì°¨ì› ë¹„êµ
        st.markdown("#### ë‹¤ì°¨ì› ë¹„êµ (ë ˆì´ë” ì°¨íŠ¸)")
        categories = ["ì •í™•ë„", "í•™ìŠµ ì†ë„", "í•´ì„ ê°€ëŠ¥ì„±", "ëª¨ë¸ ê²½ëŸ‰ì„±", "ë©€í‹°ëª¨ë‹¬"]
        radar_models = [
            {"name": "LightGBM (ML)", "vals": [3.96, 5.0, 5.0, 3.0, 2.0], "color": "#3B82F6"},
            {"name": "CNN+Transformer (DL)", "vals": [2.75, 1.5, 1.5, 1.5, 5.0], "color": "#F59E0B"},
            {"name": "Stacking (Ensemble)", "vals": [3.96, 2.0, 3.0, 5.0, 4.0], "color": "#EF4444"},
        ]
        fig = go.Figure()
        for rm in radar_models:
            fig.add_trace(go.Scatterpolar(
                r=rm["vals"] + [rm["vals"][0]],
                theta=categories + [categories[0]],
                fill="toself", name=rm["name"], opacity=0.5,
                line=dict(color=rm["color"], width=2),
            ))
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 5])),
            height=450, margin=dict(l=40, r=40, t=10, b=0),
            paper_bgcolor="rgba(0,0,0,0)",
            legend=dict(orientation="h", y=-0.1),
        )
        st.plotly_chart(fig, use_container_width=True)

        st.divider()

        st.markdown("#### ìµœì¢… ë°°í¬ ì „ëµ")
        st.success("""**ìµœì¢… ê²°ë¡ : 3-ëª¨ë¸ í˜‘ì—… êµ¬ì¡°**

| ì—­í•  | ëª¨ë¸ | ì´ìœ  |
|------|------|------|
| **ì •í™•ë„ (ì˜ˆì¸¡)** | LightGBM (96.89%) | ì„¼ì„œ í”¼ì²˜ ê¸°ë°˜ ìµœê³  ì •í™•ë„ |
| **ë©€í‹°ëª¨ë‹¬ (ë°°í¬)** | CNN+Transformer (93.24%) | ì—´í™”ìƒ ì´ë¯¸ì§€ ì§ì ‘ ì²˜ë¦¬ ê°€ëŠ¥ |
| **í•´ì„ë ¥ (ì§„ë‹¨)** | Gemini 2.5 Flash | ì„¼ì„œ ë°ì´í„° í•´ì„ + ì¡°ì¹˜ ì¶”ì²œ |
""")

        st.markdown("""
**ë°°í¬ ëª¨ë¸ ì„ íƒ ê·¼ê±°:**

| í•­ëª© | CNN+Transformer (ë°°í¬) | LightGBM (ìµœê³  ì •í™•ë„) |
|------|------------------------|----------------------|
| **ì •í™•ë„** | 93.24% | 96.89% |
| **ë©€í‹°ëª¨ë‹¬** | ì„¼ì„œ + ì—´í™”ìƒ + ì™¸ë¶€í™˜ê²½ | ì„¼ì„œë§Œ (í”¼ì²˜ ì¶”ì¶œ í•„ìš”) |
| **ì—´í™”ìƒ ì²˜ë¦¬** | CNNìœ¼ë¡œ ì§ì ‘ ì²˜ë¦¬ | ë¶ˆê°€ëŠ¥ |
| **ì„ íƒ ì´ìœ ** | ì—´í™”ìƒ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆì–´ ì‹¤ì œ í™˜ê²½ì—ì„œ ë” ìœ ë¦¬ | - |
""")


# ============================================================
# íƒ­ 3: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ëŒ€ì‹œë³´ë“œ + ì¥ë¹„ ìƒì„¸ í†µí•©)
# ============================================================
with tab3:
    sb = get_supabase()

    eq_result = sb.table("equipment").select("*").order("id").execute()
    equipment_list = eq_result.data

    if not equipment_list:
        st.info("ë“±ë¡ëœ ì¥ë¹„ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # --- ì¥ë¹„ ì „ì²´ í˜„í™© í…Œì´ë¸” (í•œëˆˆì— íŒŒì•…) ---
        eq_rows = []
        for e in equipment_list:
            s = e.get("state", 0)
            # ìµœì‹  ì„¼ì„œ 1ê±´ ì¡°íšŒ
            sen = sb.table("sensor_data").select("ntc, pm2_5, ct1").eq(
                "equipment_id", e["id"]).order("recorded_at", desc=True).limit(1).execute()
            sd = sen.data[0] if sen.data else {}
            ntc_val = sd.get("ntc", 0) or 0
            pm_val = sd.get("pm2_5", 0) or 0
            ct_val = sd.get("ct1", 0) or 0
            eq_rows.append({
                "ìƒíƒœ": f"{STATE_ICONS.get(s, 'âšª')} {STATE_LABELS.get(s, '')}",
                "ì¥ë¹„": e["id"],
                "ìœ„ì¹˜": e.get("location", ""),
                "NTC": f"{ntc_val:.1f}Â°C",
                "PM2.5": f"{pm_val:.0f}",
                "CT1": f"{ct_val:.1f}A",
                "ì˜ˆì¸¡ ì‹ ë¢°ë„": f"{e.get('confidence', 0):.0%}" if e.get("confidence") else "-",
            })
        st.dataframe(pd.DataFrame(eq_rows), use_container_width=True, hide_index=True)
        st.caption("ì˜ˆì¸¡ ì‹ ë¢°ë„: LightGBM ëª¨ë¸ì˜ ì—´í™” ìƒíƒœ ì˜ˆì¸¡ í™•ë¥ ")

        st.divider()

        # --- ì¥ë¹„ ì„ íƒ â†’ ìƒì„¸ ---
        eq_options = {f"{e['id']} - {e.get('name', '')}": e["id"] for e in equipment_list}
        selected = st.selectbox("ì¥ë¹„ ì„ íƒ", list(eq_options.keys()), key="monitor_eq_select")
        eq_id = eq_options[selected]

        detail = sb.table("equipment").select("*").eq("id", eq_id).execute()
        eq = detail.data[0] if detail.data else {}
        state = eq.get("state", 0)

        # ìƒíƒœ í•œ ì¤„ í‘œì‹œ
        conf = eq.get("confidence", 0)
        conf_str = f" Â· ì‹ ë¢°ë„ {conf:.0%}" if conf else ""
        st.markdown(f"**{STATE_ICONS.get(state, '')} {STATE_LABELS.get(state, '')}**{conf_str} Â· {eq.get('type', '')} Â· {eq.get('location', '')}")

        # --- ì„¼ì„œ í˜„í™© ---
        latest = (
            sb.table("sensor_data").select("*")
            .eq("equipment_id", eq_id)
            .order("recorded_at", desc=True).limit(1).execute()
        )

        if latest.data:
            s = latest.data[0]
            sensor_config = [
                ("NTC", "ntc", 100, 50, "Â°C"),
                ("PM1.0", "pm1_0", 500, 200, "Î¼g/mÂ³"),
                ("PM2.5", "pm2_5", 500, 35, "Î¼g/mÂ³"),
                ("PM10", "pm10", 500, 100, "Î¼g/mÂ³"),
                ("CT1", "ct1", 200, 100, "A"),
                ("CT2", "ct2", 200, 100, "A"),
                ("CT3", "ct3", 200, 100, "A"),
                ("CT4", "ct4", 200, 100, "A"),
            ]
            cols = st.columns(4)
            for i, (label, key, max_v, threshold, unit) in enumerate(sensor_config):
                val = s.get(key, 0) or 0
                over = val >= threshold
                with cols[i % 4]:
                    st.metric(label, f"{val:.1f} {unit}",
                              delta=f"ì„ê³„ {threshold} ì´ˆê³¼" if over else None,
                              delta_color="inverse" if over else "off")
        else:
            st.info("ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # --- ì„¼ì„œ íŠ¸ë Œë“œ ---
        history = (
            sb.table("sensor_data")
            .select("ntc, pm2_5, ct1, recorded_at")
            .eq("equipment_id", eq_id)
            .order("recorded_at", desc=True).limit(60).execute()
        )

        if history.data and len(history.data) > 1:
            df = pd.DataFrame(list(reversed(history.data)))
            df["recorded_at"] = pd.to_datetime(df["recorded_at"])
            df["index"] = range(len(df))

            chart_col1, chart_col2, chart_col3 = st.columns(3)

            with chart_col1:
                fig = px.line(df, x="index", y="ntc", title="NTC (Â°C)")
                fig.add_hline(y=50, line_dash="dash", line_color="red")
                fig.update_layout(height=200, margin=dict(l=0, r=0, t=30, b=0),
                                  paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                                  showlegend=False, xaxis_title="", yaxis_title="")
                st.plotly_chart(fig, use_container_width=True)

            with chart_col2:
                fig = px.line(df, x="index", y="pm2_5", title="PM2.5")
                fig.add_hline(y=35, line_dash="dash", line_color="red")
                fig.update_layout(height=200, margin=dict(l=0, r=0, t=30, b=0),
                                  paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                                  showlegend=False, xaxis_title="", yaxis_title="")
                st.plotly_chart(fig, use_container_width=True)

            with chart_col3:
                fig = px.line(df, x="index", y="ct1", title="CT1 (A)")
                fig.add_hline(y=100, line_dash="dash", line_color="red")
                fig.update_layout(height=200, margin=dict(l=0, r=0, t=30, b=0),
                                  paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
                                  showlegend=False, xaxis_title="", yaxis_title="")
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # --- ì•Œë¦¼ ---
        alerts_result = sb.table("alerts").select("*").eq("equipment_id", eq_id).order("created_at", desc=True).limit(5).execute()
        if alerts_result.data:
            with st.expander(f"ì•Œë¦¼ ({len(alerts_result.data)}ê±´)"):
                for alert in alerts_result.data:
                    level = alert.get("level", "minor")
                    icon = {"severe": "ğŸ”´", "moderate": "ğŸŸ ", "minor": "ğŸŸ¡"}.get(level, "âšª")
                    st.markdown(f"{icon} {alert.get('message', '')} Â· {alert.get('created_at', '')[:16]}")

        # ============================================================
        # AI ì§„ë‹¨ ì„¹ì…˜ (Tab 3ì— í†µí•©)
        # ============================================================
        st.divider()

        # ì„¼ì„œ ë°ì´í„° ì¤€ë¹„ (Tab 3ì—ì„œ ì´ë¯¸ ë¡œë“œëœ latest ì‚¬ìš©)
        sensors = latest.data[0] if latest.data else None
        current_state = state
        current_conf = eq.get("confidence", 0)

        if st.button("ğŸ¤– AI ì§„ë‹¨ ì‹¤í–‰", type="primary", use_container_width=True):
            if not sensors:
                st.warning("ì„¼ì„œ ë°ì´í„°ê°€ ì—†ì–´ ì§„ë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                gemini_key = st.secrets.get("GEMINI_API_KEY", os.environ.get("GEMINI_API_KEY", ""))
                if not gemini_key:
                    st.error("GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”. (Streamlit Cloud: Secrets ë©”ë‰´ / ë¡œì»¬: .env íŒŒì¼)")
                else:
                    with st.spinner("Gemini 2.5 Flashë¡œ ì§„ë‹¨ ì¤‘..."):
                        try:
                            import google.generativeai as genai
                            genai.configure(api_key=gemini_key)
                            model = genai.GenerativeModel("gemini-2.5-flash")

                            prediction = STATE_LABELS.get(current_state, "ì •ìƒ")
                            confidence = current_conf or 0.5

                            prompt = f"""ë‹¹ì‹ ì€ ì œì¡°ì„¤ë¹„ ì˜ˆì§€ë³´ì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë„ì²´ ì´ì†¡ì¥ì¹˜ì˜ ì„¼ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì²´ê³„ì ì¸ ì§„ë‹¨ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

## ì¥ë¹„ ì •ë³´
- ì¥ë¹„ ID: {eq_id}
- AI ì˜ˆì¸¡ ì—´í™” ìƒíƒœ: {prediction} (ì‹ ë¢°ë„ {confidence:.1%})

## í˜„ì¬ ì„¼ì„œ ë°ì´í„°
| ì„¼ì„œ | ì¸¡ì •ê°’ | ì„ê³„ê°’ | ìƒíƒœ |
|------|--------|--------|------|
| NTC (ì˜¨ë„) | {sensors.get('ntc', 0):.1f}Â°C | 50Â°C ì£¼ì˜ / 70Â°C ìœ„í—˜ | {'ì´ìƒ' if (sensors.get('ntc', 0) or 0) >= 50 else 'ì •ìƒ'} |
| PM1.0 | {sensors.get('pm1_0', 0):.0f} Î¼g/mÂ³ | 200 ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('pm1_0', 0) or 0) >= 200 else 'ì •ìƒ'} |
| PM2.5 | {sensors.get('pm2_5', 0):.0f} Î¼g/mÂ³ | 35 ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('pm2_5', 0) or 0) >= 35 else 'ì •ìƒ'} |
| PM10 | {sensors.get('pm10', 0):.0f} Î¼g/mÂ³ | 100 ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('pm10', 0) or 0) >= 100 else 'ì •ìƒ'} |
| CT1 (ì „ë¥˜) | {sensors.get('ct1', 0):.1f}A | 100A ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('ct1', 0) or 0) >= 100 else 'ì •ìƒ'} |
| CT2 | {sensors.get('ct2', 0):.1f}A | 100A ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('ct2', 0) or 0) >= 100 else 'ì •ìƒ'} |
| CT3 | {sensors.get('ct3', 0):.1f}A | 100A ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('ct3', 0) or 0) >= 100 else 'ì •ìƒ'} |
| CT4 | {sensors.get('ct4', 0):.1f}A | 100A ì£¼ì˜ | {'ì´ìƒ' if (sensors.get('ct4', 0) or 0) >= 100 else 'ì •ìƒ'} |

## ì‘ì—…
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

{{
  "severity": "ì •ìƒ/ì£¼ì˜/ê²½ê³ /ìœ„í—˜ ì¤‘ í•˜ë‚˜",
  "sensor_analysis": [
    {{"sensor": "ì„¼ì„œëª…", "value": "ì¸¡ì •ê°’", "status": "ì •ìƒ/ì£¼ì˜/ìœ„í—˜", "detail": "êµ¬ì²´ì  ë¶„ì„"}}
  ],
  "anomalies": ["ì´ìƒ ì§•í›„ ìš”ì•½ 1", "ì´ìƒ ì§•í›„ ìš”ì•½ 2"],
  "probable_causes": [
    {{"cause": "ì›ì¸ ì„¤ëª…", "likelihood": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ"}}
  ],
  "recommended_actions": [
    {{"priority": "ì¦‰ì‹œ/ë‹¨ê¸°/ì˜ˆë°©", "action": "ì¡°ì¹˜ ë‚´ìš©"}}
  ],
  "summary": "ì „ì²´ ì§„ë‹¨ ìš”ì•½ (2-3ë¬¸ì¥)"
}}

ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ê° ì„¼ì„œë³„ë¡œ ë¶„ì„í•˜ê³ , ì›ì¸ê³¼ ì¡°ì¹˜ëŠ” ìš°ì„ ìˆœìœ„ë¥¼ í¬í•¨í•˜ì„¸ìš”."""

                            response = model.generate_content(prompt)
                            text = response.text.strip()

                            # JSON ì¶”ì¶œ
                            if text.startswith("```"):
                                lines = text.split("\n")
                                text = "\n".join(lines[1:-1])

                            try:
                                result = json.loads(text)
                            except json.JSONDecodeError:
                                result = {
                                    "severity": "ì•Œ ìˆ˜ ì—†ìŒ",
                                    "anomalies": [text[:300]],
                                    "probable_causes": [{"cause": "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨", "likelihood": "-"}],
                                    "recommended_actions": [{"priority": "ì¦‰ì‹œ", "action": "ìˆ˜ë™ ì ê²€ í•„ìš”"}],
                                    "summary": "LLM ì‘ë‹µ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                                }

                            # --- ê²°ê³¼ í‘œì‹œ ---
                            severity = result.get("severity", "ì•Œ ìˆ˜ ì—†ìŒ")
                            sev_colors = {"ì •ìƒ": "success", "ì£¼ì˜": "warning", "ê²½ê³ ": "warning", "ìœ„í—˜": "error"}
                            sev_func = getattr(st, sev_colors.get(severity, "info"))
                            sev_func(f"**ì§„ë‹¨ ê²°ê³¼: {severity}**")

                            # ìš”ì•½
                            if result.get("summary"):
                                st.markdown(f"> {result['summary']}")

                            # ì„¼ì„œë³„ ë¶„ì„ â€” ì´ìƒ ì„¼ì„œë§Œ ì¹´ë“œë¡œ, ì •ìƒì€ ì ‘ê¸°
                            if result.get("sensor_analysis"):
                                abnormal = [sa for sa in result["sensor_analysis"] if sa.get("status") != "ì •ìƒ"]
                                normal = [sa for sa in result["sensor_analysis"] if sa.get("status") == "ì •ìƒ"]

                                if abnormal:
                                    st.markdown("#### ì´ìƒ ê°ì§€ ì„¼ì„œ")
                                    for sa in abnormal:
                                        with st.container(border=True):
                                            sc1, sc2 = st.columns([1, 3])
                                            with sc1:
                                                st.metric(sa.get("sensor", ""), sa.get("value", ""), delta=sa.get("status", ""))
                                            with sc2:
                                                st.markdown(sa.get("detail", ""))

                                if normal:
                                    with st.expander(f"ì •ìƒ ì„¼ì„œ ({len(normal)}ê°œ)"):
                                        for sa in normal:
                                            st.markdown(f"**{sa.get('sensor', '')}** {sa.get('value', '')} â€” {sa.get('detail', '')}")

                            # ì´ìƒ ì§•í›„
                            if result.get("anomalies"):
                                st.markdown("#### ì´ìƒ ì§•í›„")
                                for a in result["anomalies"]:
                                    st.markdown(f"- {a}")

                            # ì˜ˆìƒ ì›ì¸ + ê¶Œì¥ ì¡°ì¹˜ â€” 2ì»¬ëŸ¼ ì¹´ë“œ
                            causes = result.get("probable_causes", [])
                            if not causes and result.get("probable_cause"):
                                causes = [{"cause": result["probable_cause"], "likelihood": "-"}]
                            actions = result.get("recommended_actions", [])
                            if not actions and result.get("recommended_action"):
                                actions = [{"priority": "ì¦‰ì‹œ", "action": result["recommended_action"]}]

                            if causes or actions:
                                st.markdown("#### ì˜ˆìƒ ì›ì¸")
                                if causes:
                                    for c in causes:
                                        with st.container(border=True):
                                            lh = c.get("likelihood", "")
                                            st.markdown(f"**ê°€ëŠ¥ì„±: {lh}** â€” {c.get('cause', '')}")
                                else:
                                    st.caption("ì •ìƒ ë²”ìœ„ â€” íŠ¹ì´ ì›ì¸ ì—†ìŒ")

                                st.markdown("#### ê¶Œì¥ ì¡°ì¹˜")
                                if actions:
                                    act_cols = st.columns(len(actions)) if len(actions) <= 3 else st.columns(3)
                                    for i, act in enumerate(actions):
                                        with act_cols[i % len(act_cols)]:
                                            with st.container(border=True):
                                                pr = act.get("priority", "")
                                                st.markdown(f"**{pr}**")
                                                st.markdown(act.get("action", ""))
                                else:
                                    st.caption("íŠ¹ë³„í•œ ì¡°ì¹˜ ë¶ˆí•„ìš”")

                            # Supabaseì— ì €ì¥
                            try:
                                cause_text = ", ".join(c.get("cause", "") for c in causes) if causes else ""
                                action_text = ", ".join(a.get("action", "") for a in actions) if actions else ""
                                sb.table("diagnosis_history").insert({
                                    "equipment_id": eq_id,
                                    "severity": result.get("severity", prediction),
                                    "prediction": current_state,
                                    "confidence": round(confidence, 3),
                                    "probable_cause": cause_text or result.get("summary", "ì§„ë‹¨ ì™„ë£Œ"),
                                    "recommended_action": action_text or "íŠ¹ë³„í•œ ì¡°ì¹˜ ë¶ˆí•„ìš”",
                                    "anomalies": result.get("anomalies", []),
                                }).execute()
                            except Exception as insert_err:
                                st.warning(f"ì§„ë‹¨ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨: {insert_err}")

                        except Exception as e:
                            st.error(f"ì§„ë‹¨ ì‹¤íŒ¨: {e}")

        # ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ â€” ìˆœìˆ˜ ì„¼ì„œ ìœ ì‚¬ë„ ê¸°ë°˜
        cases_path = PROJECT_ROOT / "llm-service" / "app" / "data" / "cases.json"
        if cases_path.exists():
            st.divider()
            st.subheader("ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€")

            with open(cases_path, "r", encoding="utf-8") as f:
                all_cases = json.load(f)

            if sensors and all_cases:
                sensor_keys = ["ntc", "pm1_0", "pm2_5", "pm10", "ct1", "ct2", "ct3", "ct4"]
                sensor_ranges = {"ntc": 100, "pm1_0": 500, "pm2_5": 500, "pm10": 500,
                                 "ct1": 200, "ct2": 200, "ct3": 200, "ct4": 200}
                vec1 = np.array([sensors.get(k, 0) / sensor_ranges[k] for k in sensor_keys], dtype=float)

                scored = []
                for case in all_cases:
                    cs = case.get("sensors", {})
                    vec2 = np.array([cs.get(k, 0) / sensor_ranges[k] for k in sensor_keys], dtype=float)
                    dist = float(np.linalg.norm(vec1 - vec2))
                    sim = max(0, round((1 - dist / 3) * 100, 1))
                    scored.append({**case, "similarity": sim})

                scored.sort(key=lambda x: x["similarity"], reverse=True)
                display_cases = scored[:3]

                case_cols = st.columns(3)
                for i, case in enumerate(display_cases):
                    sev = case.get("severity", "")
                    sev_icon = {"ì‹¬ê°": "ğŸ”´", "ì¤‘ê°„": "ğŸŸ ", "ê²½ë¯¸": "ğŸŸ¡"}.get(sev, "âšª")
                    with case_cols[i]:
                        with st.container(border=True):
                            st.markdown(f"**{sev_icon} {sev}** Â· ìœ ì‚¬ë„ {case['similarity']}%")
                            st.caption(f"{case.get('case_id', '')} | {case.get('date', '')}")
                            st.markdown(f"**ë¬¸ì œ**: {case.get('issue', '')}")
                            st.markdown(f"**ì¡°ì¹˜**: {case.get('action', '')}")

        # ì§„ë‹¨ ì´ë ¥
        st.divider()
        from datetime import datetime, timedelta, timezone
        KST = timezone(timedelta(hours=9))

        st.subheader("ì§„ë‹¨ ì´ë ¥")

        # ì‚­ì œ ì²˜ë¦¬ (session_state ê¸°ë°˜ â€” rerun í›„ ì‹¤í–‰)
        if st.session_state.get("_delete_diag_id"):
            try:
                sb.table("diagnosis_history").delete().eq("id", st.session_state["_delete_diag_id"]).execute()
            except Exception:
                pass
            st.session_state["_delete_diag_id"] = None

        if st.session_state.get("_delete_diag_all"):
            try:
                sb.table("diagnosis_history").delete().eq("equipment_id", st.session_state["_delete_diag_all"]).execute()
            except Exception:
                pass
            st.session_state["_delete_diag_all"] = None

        diag_result = (
            sb.table("diagnosis_history")
            .select("*")
            .eq("equipment_id", eq_id)
            .order("created_at", desc=True)
            .limit(10)
            .execute()
        )
        if diag_result.data:
            clear_col = st.columns([8, 1])
            with clear_col[1]:
                if st.button("ì „ì²´ ì‚­ì œ", key="diag_clear_all"):
                    st.session_state["_delete_diag_all"] = eq_id
                    st.rerun()

            for d in diag_result.data:
                raw_ts = d.get("created_at", "")
                try:
                    utc_dt = datetime.fromisoformat(raw_ts.replace("Z", "+00:00"))
                    kst_dt = utc_dt.astimezone(KST)
                    ts = kst_dt.strftime("%Y-%m-%d %H:%M")
                except Exception:
                    ts = raw_ts[:16].replace("T", " ")
                sev = d.get("severity", "")
                d_id = d.get("id")
                with st.container(border=True):
                    st.markdown(f"**{sev}** Â· {ts}")
                    hc1, hc2, hc3 = st.columns([5, 5, 1])
                    with hc1:
                        st.markdown(f"**ì›ì¸**: {d.get('probable_cause', '') or '-'}")
                    with hc2:
                        st.markdown(f"**ì¡°ì¹˜**: {d.get('recommended_action', '') or '-'}")
                    with hc3:
                        if st.button("ì‚­ì œ", key=f"del_{d_id}"):
                            st.session_state["_delete_diag_id"] = d_id
                            st.rerun()
        else:
            st.info("ì§„ë‹¨ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")


# --- Footer ---
st.divider()
st.caption("ConveyorGuard v1.0 | LightGBM 96.89% + CNN+Transformer 93.24% + Gemini 2.5 Flash | Supabase")
