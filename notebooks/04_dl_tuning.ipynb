{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConveyorGuard - 04. DL Tuning (Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”)\n",
    "\n",
    "**Optuna ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” â†’ 95%+ ëª©í‘œ**\n",
    "\n",
    "- **Accelerator: GPU T4 x2**\n",
    "- ì…ë ¥: `train_data.joblib`, `val_data.joblib`, `test_data.joblib`\n",
    "- ì¶œë ¥: `tuned_model.pt`, `optuna_study.pkl`\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline\n",
    "> `00_eda` â†’ `01_preprocess` â†’ `02/03`(ë³‘ë ¬) â†’ **`04_dl_tuning`** â†’ `05_llm_comparison`\n",
    "\n",
    "| ì…ë ¥ ë°ì´í„°ì…‹ | ì¶œë ¥ | Accelerator |\n",
    "|--------------|------|-------------|\n",
    "| `conveyorguard-preprocess` (01 ì¶œë ¥) | `tuned_model.pt`, `optuna_study.pkl` | GPU T4 x2 |\n",
    "\n",
    "### ëª¨ë¸ ì•„í‚¤í…ì²˜\n",
    "```\n",
    "Sensor (30,8) â†’ MLP â†’ TemporalEncoder\n",
    "                            â†“\n",
    "                      CrossAttention â†’ FiLM(External) â†’ Classifier â†’ 4-Class\n",
    "                            â†‘\n",
    "Image (10,60,80) â†’ CNN â†’ TemporalEncoder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:31:16.352982Z",
     "iopub.status.busy": "2026-02-01T07:31:16.352196Z",
     "iopub.status.idle": "2026-02-01T07:31:26.952208Z",
     "shell.execute_reply": "2026-02-01T07:31:26.951523Z",
     "shell.execute_reply.started": "2026-02-01T07:31:16.352949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "PyTorch: 2.8.0+cu126\n",
      "CUDA: 12.6\n",
      "\n",
      "ğŸ–¥ï¸ Device: cuda\n",
      "   GPU 0: Tesla T4 (15637086208.0 GB)\n",
      "   GPU 1: Tesla T4 (15637086208.0 GB)\n",
      "   Total GPUs: 2\n",
      "   cuDNN benchmark: enabled\n",
      "   float32 matmul precision: medium\n",
      "\n",
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install optuna plotly -q\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import time\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotly ì„¤ì •\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# í™˜ê²½ ì •ë³´\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "\n",
    "# GPU í™•ì¸ (T4 x2 ì§€ì›)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nğŸ–¥ï¸ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"   GPU {i}: {props.name} ({getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0) / 1024**3:.1f} GB)\")\n",
    "    print(f\"   Total GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# âš¡ ì†ë„ ìµœì í™”\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "print(f\"   cuDNN benchmark: enabled\")\n",
    "print(f\"   float32 matmul precision: medium\")\n",
    "\n",
    "print(f\"\\nâœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ì‹œì‘\n",
    "_notebook_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:31:26.953774Z",
     "iopub.status.busy": "2026-02-01T07:31:26.953544Z",
     "iopub.status.idle": "2026-02-01T07:31:26.960028Z",
     "shell.execute_reply": "2026-02-01T07:31:26.959226Z",
     "shell.execute_reply.started": "2026-02-01T07:31:26.953752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° í´ë”: /kaggle/input/conveyorguard-preprocess\n",
      "ğŸ“ ì¶œë ¥ í´ë”: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "# ê²½ë¡œ ì„¤ì • (fallback ì§€ì›)\n",
    "DATA_DIR = Path('/kaggle/input/conveyorguard-preprocess')\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR = Path('/kaggle/input/preprocess')\n",
    "OUTPUT_DIR = Path('/kaggle/working')\n",
    "\n",
    "print(f\"ğŸ“‚ ë°ì´í„° í´ë”: {DATA_DIR}\")\n",
    "print(f\"ğŸ“ ì¶œë ¥ í´ë”: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:31:26.961368Z",
     "iopub.status.busy": "2026-02-01T07:31:26.961048Z",
     "iopub.status.idle": "2026-02-01T07:32:11.363961Z",
     "shell.execute_reply": "2026-02-01T07:32:11.363149Z",
     "shell.execute_reply.started": "2026-02-01T07:31:26.961334Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "\n",
      "ğŸ“Š ë°ì´í„° í¬ê¸°:\n",
      "   Train: 7,311ê°œ\n",
      "   Val: 1,554ê°œ\n",
      "   Test: 1,608ê°œ\n",
      "\n",
      "ğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬ (Train):\n",
      "   Class 0: 3,586 (49.0%)\n",
      "   Class 1: 1,682 (23.0%)\n",
      "   Class 2: 1,642 (22.5%)\n",
      "   Class 3: 401 (5.5%)\n"
     ]
    }
   ],
   "source": [
    "# joblib ë¡œë“œ\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "train_data = joblib.load(DATA_DIR / 'train_data.joblib')\n",
    "val_data = joblib.load(DATA_DIR / 'val_data.joblib')\n",
    "test_data = joblib.load(DATA_DIR / 'test_data.joblib')\n",
    "\n",
    "print(f\"\\nğŸ“Š ë°ì´í„° í¬ê¸°:\")\n",
    "print(f\"   Train: {train_data['sensors'].shape[0]:,}ê°œ\")\n",
    "print(f\"   Val: {val_data['sensors'].shape[0]:,}ê°œ\")\n",
    "print(f\"   Test: {test_data['sensors'].shape[0]:,}ê°œ\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬\n",
    "print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬ (Train):\")\n",
    "unique, counts = np.unique(train_data['labels'], return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"   Class {u}: {c:,} ({c/len(train_data['labels'])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset (ìµœì í™”: ì´ë¯¸ì§€ ì„œë¸Œìƒ˜í”Œë§)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:32:11.365224Z",
     "iopub.status.busy": "2026-02-01T07:32:11.364925Z",
     "iopub.status.idle": "2026-02-01T07:32:11.997731Z",
     "shell.execute_reply": "2026-02-01T07:32:11.996842Z",
     "shell.execute_reply.started": "2026-02-01T07:32:11.365189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset ìƒì„± ì™„ë£Œ (ì´ë¯¸ì§€ 10í”„ë ˆì„)\n",
      "   Train: 7,311ê°œ\n",
      "   Val: 1,554ê°œ\n",
      "   Test: 1,608ê°œ\n",
      "   ì´ë¯¸ì§€ shape: torch.Size([7311, 10, 60, 80])\n"
     ]
    }
   ],
   "source": [
    "class ConveyorDatasetOptimized(Dataset):\n",
    "    \"\"\"\n",
    "    ìµœì í™”ëœ Dataset\n",
    "    - ì´ë¯¸ì§€: 30í”„ë ˆì„ â†’ 10í”„ë ˆì„ ì„œë¸Œìƒ˜í”Œë§ (3ë°° ë¹¨ë¼ì§)\n",
    "    \"\"\"\n",
    "    def __init__(self, data: dict, image_frames: int = 10):\n",
    "        self.sensors = torch.FloatTensor(data['sensors'])\n",
    "        \n",
    "        # âš¡ ì´ë¯¸ì§€ ì„œë¸Œìƒ˜í”Œë§ (30 â†’ 10 í”„ë ˆì„)\n",
    "        images = data['images']\n",
    "        indices = np.linspace(0, images.shape[1]-1, image_frames, dtype=int)\n",
    "        self.images = torch.FloatTensor(images[:, indices, :, :])\n",
    "        \n",
    "        self.externals = torch.FloatTensor(data['external'])\n",
    "        self.labels = torch.LongTensor(data['labels'])\n",
    "        \n",
    "        self.image_frames = image_frames\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'sensors': self.sensors[idx],\n",
    "            'images': self.images[idx],\n",
    "            'externals': self.externals[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Dataset ìƒì„±\n",
    "IMAGE_FRAMES = 10  # 30 â†’ 10 (ìµœì í™”)\n",
    "\n",
    "train_dataset = ConveyorDatasetOptimized(train_data, image_frames=IMAGE_FRAMES)\n",
    "val_dataset = ConveyorDatasetOptimized(val_data, image_frames=IMAGE_FRAMES)\n",
    "test_dataset = ConveyorDatasetOptimized(test_data, image_frames=IMAGE_FRAMES)\n",
    "\n",
    "print(f\"âœ… Dataset ìƒì„± ì™„ë£Œ (ì´ë¯¸ì§€ {IMAGE_FRAMES}í”„ë ˆì„)\")\n",
    "print(f\"   Train: {len(train_dataset):,}ê°œ\")\n",
    "print(f\"   Val: {len(val_dataset):,}ê°œ\")\n",
    "print(f\"   Test: {len(test_dataset):,}ê°œ\")\n",
    "print(f\"   ì´ë¯¸ì§€ shape: {train_dataset.images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ ì •ì˜ (ì´ë¯¸ì§€ í”„ë ˆì„ ìˆ˜ ì¡°ì •)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:32:11.999802Z",
     "iopub.status.busy": "2026-02-01T07:32:11.999517Z",
     "iopub.status.idle": "2026-02-01T07:32:12.017957Z",
     "shell.execute_reply": "2026-02-01T07:32:12.017264Z",
     "shell.execute_reply.started": "2026-02-01T07:32:11.999781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ (FiLM: Feature-wise Linear Modulation)\n"
     ]
    }
   ],
   "source": [
    "class SensorEncoder(nn.Module):\n",
    "    \"\"\"ì„¼ì„œ ë°ì´í„° ì¸ì½”ë” (MLP)\"\"\"\n",
    "    def __init__(self, input_dim=8, embed_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    \"\"\"ì—´í™”ìƒ ì´ë¯¸ì§€ ì¸ì½”ë” (CNN)\"\"\"\n",
    "    def __init__(self, embed_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(dropout),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(dropout),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.proj = nn.Linear(128, embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, H, W = x.shape\n",
    "        x = x.view(B * T, 1, H, W)\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(B * T, -1)\n",
    "        x = self.proj(x)\n",
    "        return x.view(B, T, -1)\n",
    "\n",
    "\n",
    "class TemporalEncoder(nn.Module):\n",
    "    \"\"\"ì‹œê³„ì—´ Transformer ì¸ì½”ë”\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=4, num_layers=2, dropout=0.1, seq_len=30):\n",
    "        super().__init__()\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, seq_len, embed_dim) * 0.02)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pos_embed[:, :x.size(1), :]\n",
    "        return self.transformer(x)\n",
    "\n",
    "\n",
    "class CrossAttentionFusion(nn.Module):\n",
    "    \"\"\"Cross-Attention ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ìœµí•©\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sensor_feat, image_feat):\n",
    "        attn_out, _ = self.cross_attn(sensor_feat, image_feat, image_feat)\n",
    "        x = self.norm1(sensor_feat + attn_out)\n",
    "        x = self.norm2(x + self.ffn(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConveyorGuardModel(nn.Module):\n",
    "    \"\"\"ì „ì²´ ëª¨ë¸ (3-modal: ì„¼ì„œ + ì—´í™”ìƒ + ì™¸ë¶€í™˜ê²½)\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=4, num_layers=2, dropout=0.1, \n",
    "                 num_classes=4, sensor_seq_len=30, image_seq_len=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sensor_encoder = SensorEncoder(input_dim=8, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.image_encoder = ImageEncoder(embed_dim=embed_dim, dropout=dropout)\n",
    "        self.external_encoder = nn.Sequential(\n",
    "            nn.Linear(3, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.sensor_temporal = TemporalEncoder(embed_dim=embed_dim, num_heads=num_heads, \n",
    "                                                num_layers=num_layers, dropout=dropout, seq_len=sensor_seq_len)\n",
    "        self.image_temporal = TemporalEncoder(embed_dim=embed_dim, num_heads=num_heads, \n",
    "                                               num_layers=num_layers, dropout=dropout, seq_len=image_seq_len)\n",
    "        self.fusion = CrossAttentionFusion(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n",
    "        \n",
    "        # External ì¡°ê±´í™” (FiLM: Feature-wise Linear Modulation)\n",
    "        self.film_gamma = nn.Linear(embed_dim, embed_dim)\n",
    "        self.film_beta = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sensors, images, externals=None):\n",
    "        sensor_feat = self.sensor_encoder(sensors)\n",
    "        image_feat = self.image_encoder(images)\n",
    "        sensor_feat = self.sensor_temporal(sensor_feat)\n",
    "        image_feat = self.image_temporal(image_feat)\n",
    "        fused = self.fusion(sensor_feat, image_feat)\n",
    "        pooled = fused.mean(dim=1)\n",
    "        \n",
    "        # FiLM ì¡°ê±´í™”: ì™¸ë¶€í™˜ê²½ìœ¼ë¡œ ì„¼ì„œ-ì´ë¯¸ì§€ ìœµí•© ê²°ê³¼ë¥¼ ë³€ì¡°\n",
    "        if externals is not None:\n",
    "            ext_feat = self.external_encoder(externals)\n",
    "            ext_pooled = ext_feat.mean(dim=1)\n",
    "            gamma = self.film_gamma(ext_pooled)\n",
    "            beta = self.film_beta(ext_pooled)\n",
    "            pooled = gamma * pooled + beta\n",
    "        \n",
    "        return self.classifier(pooled)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ (FiLM: Feature-wise Linear Modulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GPU ìµœì í™” í•™ìŠµ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:32:12.019218Z",
     "iopub.status.busy": "2026-02-01T07:32:12.018896Z",
     "iopub.status.idle": "2026-02-01T07:32:12.036668Z",
     "shell.execute_reply": "2026-02-01T07:32:12.035981Z",
     "shell.execute_reply.started": "2026-02-01T07:32:12.019197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: [0.28 0.6  0.61 2.51]\n"
     ]
    }
   ],
   "source": [
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "train_labels = train_data['labels']\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "print(f\"ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:32:12.037942Z",
     "iopub.status.busy": "2026-02-01T07:32:12.037673Z",
     "iopub.status.idle": "2026-02-01T07:32:12.050115Z",
     "shell.execute_reply": "2026-02-01T07:32:12.049485Z",
     "shell.execute_reply.started": "2026-02-01T07:32:12.037921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•™ìŠµ/í‰ê°€ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (AMP + DataParallel)\n"
     ]
    }
   ],
   "source": [
    "def train_epoch_optimized(model, loader, criterion, optimizer, device, scaler=None):\n",
    "    \"\"\"GPU ìµœì í™” í•™ìŠµ í•¨ìˆ˜ (AMP + DataParallel)\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        sensors = batch['sensors'].to(device, non_blocking=True)\n",
    "        images = batch['images'].to(device, non_blocking=True)\n",
    "        externals = batch['externals'].to(device, non_blocking=True)\n",
    "        labels = batch['label'].to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                logits = model(sensors, images, externals)\n",
    "                loss = criterion(logits, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(sensors, images, externals)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        correct += (logits.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total * 100\n",
    "\n",
    "\n",
    "def evaluate_optimized(model, loader, criterion, device):\n",
    "    \"\"\"GPU í‰ê°€ í•¨ìˆ˜\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sensors = batch['sensors'].to(device, non_blocking=True)\n",
    "            images = batch['images'].to(device, non_blocking=True)\n",
    "            externals = batch['externals'].to(device, non_blocking=True)\n",
    "            labels = batch['label'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                logits = model(sensors, images, externals)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            correct += (logits.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total * 100\n",
    "\n",
    "print(\"âœ… í•™ìŠµ/í‰ê°€ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (AMP + DataParallel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna Objective í•¨ìˆ˜ (ìµœì í™”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:32:12.051349Z",
     "iopub.status.busy": "2026-02-01T07:32:12.051026Z",
     "iopub.status.idle": "2026-02-01T07:32:12.067894Z",
     "shell.execute_reply": "2026-02-01T07:32:12.067165Z",
     "shell.execute_reply.started": "2026-02-01T07:32:12.051319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Objective í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "   Batch size: 64 (GPUë‹¹ 32)\n",
      "   DataParallel: True\n"
     ]
    }
   ],
   "source": [
    "# ê³ ì • í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "FIXED_BATCH_SIZE = 64  # T4 x2: GPUë‹¹ 32\n",
    "FIXED_EPOCHS = 10      # ë¹ ë¥¸ íƒìƒ‰\n",
    "FIXED_PATIENCE = 3     # Early stopping\n",
    "NUM_WORKERS = 4\n",
    "IMAGE_FRAMES = 10\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective í•¨ìˆ˜ (GPU T4 x2 + AMP)\"\"\"\n",
    "    \n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§\n",
    "    embed_dim = trial.suggest_categorical('embed_dim', [128, 256])\n",
    "    num_heads = trial.suggest_categorical('num_heads', [4, 8])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.3, step=0.1)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=FIXED_BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=NUM_WORKERS,\n",
    "                              pin_memory=True, persistent_workers=True,\n",
    "                              drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=FIXED_BATCH_SIZE,\n",
    "                            shuffle=False, num_workers=NUM_WORKERS,\n",
    "                            pin_memory=True, persistent_workers=True)\n",
    "    \n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    model = ConveyorGuardModel(\n",
    "        embed_dim=embed_dim,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        num_classes=4,\n",
    "        image_seq_len=IMAGE_FRAMES\n",
    "    )\n",
    "    \n",
    "    # âš¡ DataParallel (T4 x2)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # AMP Scaler\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "    \n",
    "    best_acc = 0\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(FIXED_EPOCHS):\n",
    "        train_loss, train_acc = train_epoch_optimized(model, train_loader, criterion, optimizer, device, scaler)\n",
    "        val_loss, val_acc = evaluate_optimized(model, val_loader, criterion, device)\n",
    "        \n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= FIXED_PATIENCE:\n",
    "                break\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del model, optimizer, criterion, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_acc\n",
    "\n",
    "print(f\"âœ… Objective í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   Batch size: {FIXED_BATCH_SIZE} (GPUë‹¹ {FIXED_BATCH_SIZE // max(torch.cuda.device_count(), 1)})\")\n",
    "print(f\"   DataParallel: {torch.cuda.device_count() > 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optuna ìµœì í™” ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T07:32:12.069538Z",
     "iopub.status.busy": "2026-02-01T07:32:12.068887Z",
     "iopub.status.idle": "2026-02-01T08:03:28.203953Z",
     "shell.execute_reply": "2026-02-01T08:03:28.203128Z",
     "shell.execute_reply.started": "2026-02-01T07:32:12.069506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-01 07:32:12,093] A new study created in memory with name: no-name-e9727a0a-1395-4375-a29b-0ed7e8da3c56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ì‹œì‘ (GPU T4 x2 ìµœì í™”)...\n",
      "   ëª©í‘œ: Val Accuracy ìµœëŒ€í™”\n",
      "   Trial ìˆ˜: 15\n",
      "   íƒ€ì„ì•„ì›ƒ: 30ë¶„\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b0a413ee3b47f9a0235cb744805b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-02-01 07:36:01,187] Trial 0 finished with value: 88.73873873873875 and parameters: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.00011430983876313228, 'weight_decay': 0.0005399484409787432}. Best is trial 0 with value: 88.73873873873875.\n",
      "[I 2026-02-01 07:41:00,093] Trial 1 finished with value: 89.83268983268984 and parameters: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001519934830130982, 'weight_decay': 2.3270677083837777e-05}. Best is trial 1 with value: 89.83268983268984.\n",
      "[I 2026-02-01 07:46:33,955] Trial 2 finished with value: 90.47619047619048 and parameters: {'embed_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.00019594972058679176, 'weight_decay': 5.4041038546473305e-05}. Best is trial 2 with value: 90.47619047619048.\n",
      "[I 2026-02-01 07:50:59,158] Trial 3 finished with value: 90.09009009009009 and parameters: {'embed_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0004050837781329676, 'weight_decay': 2.1930485556643678e-05}. Best is trial 2 with value: 90.47619047619048.\n",
      "[I 2026-02-01 07:53:33,202] Trial 4 pruned. \n",
      "[I 2026-02-01 07:56:47,890] Trial 5 pruned. \n",
      "[I 2026-02-01 07:59:32,491] Trial 6 pruned. \n",
      "[I 2026-02-01 08:02:47,887] Trial 7 pruned. \n",
      "============================================================\n",
      "\n",
      "â±ï¸ ì´ íƒìƒ‰ ì‹œê°„: 31.3ë¶„\n"
     ]
    }
   ],
   "source": [
    "# âš¡ ìµœì í™”ëœ ì„¤ì •\n",
    "N_TRIALS = 15  # 30 â†’ 15 (ì‹œê°„ ë‹¨ì¶•)\n",
    "TIMEOUT = 1800  # 30ë¶„ íƒ€ì„ì•„ì›ƒ\n",
    "\n",
    "# Optuna Study ìƒì„±\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=3)\n",
    ")\n",
    "\n",
    "print(\"ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ì‹œì‘ (GPU T4 x2 ìµœì í™”)...\")\n",
    "print(f\"   ëª©í‘œ: Val Accuracy ìµœëŒ€í™”\")\n",
    "print(f\"   Trial ìˆ˜: {N_TRIALS}\")\n",
    "print(f\"   íƒ€ì„ì•„ì›ƒ: {TIMEOUT//60}ë¶„\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ìµœì í™” ì‹¤í–‰\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=N_TRIALS,\n",
    "    timeout=TIMEOUT,\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True\n",
    ")\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nâ±ï¸ ì´ íƒìƒ‰ ì‹œê°„: {total_time:.1f}ë¶„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:03:28.205866Z",
     "iopub.status.busy": "2026-02-01T08:03:28.205334Z",
     "iopub.status.idle": "2026-02-01T08:03:28.559235Z",
     "shell.execute_reply": "2026-02-01T08:03:28.558605Z",
     "shell.execute_reply.started": "2026-02-01T08:03:28.205821Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Best Val Accuracy: 90.48%\n",
      "\n",
      "ğŸ“‹ Best Parameters:\n",
      "   embed_dim: 256\n",
      "   num_heads: 4\n",
      "   num_layers: 2\n",
      "   dropout: 0.1\n",
      "   lr: 0.00019594972058679176\n",
      "   weight_decay: 5.4041038546473305e-05\n",
      "\n",
      "ğŸ“ˆ Top 5 Trials:\n",
      "   number      value  params_embed_dim  params_lr  params_dropout\n",
      "2       2  90.476190               256   0.000196             0.1\n",
      "3       3  90.090090               256   0.000405             0.1\n",
      "1       1  89.832690               256   0.000152             0.1\n",
      "0       0  88.738739               256   0.000114             0.1\n",
      "5       5  86.486486               256   0.000205             0.2\n"
     ]
    }
   ],
   "source": [
    "# ìµœì  ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f\"\\nğŸ“Š Best Val Accuracy: {best_trial.value:.2f}%\")\n",
    "print(f\"\\nğŸ“‹ Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# ìƒìœ„ 5ê°œ Trial\n",
    "print(f\"\\nğŸ“ˆ Top 5 Trials:\")\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df = trials_df.sort_values('value', ascending=False)\n",
    "print(trials_df[['number', 'value', 'params_embed_dim', 'params_lr', 'params_dropout']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ìµœì  ëª¨ë¸ ì¬í•™ìŠµ (ë” ë§ì€ Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:03:28.560548Z",
     "iopub.status.busy": "2026-02-01T08:03:28.560135Z",
     "iopub.status.idle": "2026-02-01T08:13:31.428834Z",
     "shell.execute_reply": "2026-02-01T08:13:31.427911Z",
     "shell.execute_reply.started": "2026-02-01T08:03:28.560524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...\n",
      "âš¡ Using 2 GPUs with DataParallel\n",
      "\n",
      "í•™ìŠµ ì‹œì‘ (Epochs: 30, Patience: 7)\n",
      "   Batch: 64 (GPUë‹¹ 32)\n",
      "   DataParallel: True\n",
      "============================================================\n",
      "Epoch  1/30 â”‚ Train: 0.5511, 77.0% â”‚ Val: 0.3728, 81.0% âœ… Best!\n",
      "Epoch  2/30 â”‚ Train: 0.3568, 84.5% â”‚ Val: 0.2961, 84.3% âœ… Best!\n",
      "Epoch  3/30 â”‚ Train: 0.3142, 86.1% â”‚ Val: 0.3123, 85.8% âœ… Best!\n",
      "Epoch  4/30 â”‚ Train: 0.3057, 86.7% â”‚ Val: 0.2670, 86.2% âœ… Best!\n",
      "Epoch  5/30 â”‚ Train: 0.2952, 87.0% â”‚ Val: 0.2895, 86.0% (no improve: 1)\n",
      "Epoch  6/30 â”‚ Train: 0.2771, 87.6% â”‚ Val: 0.2597, 89.1% âœ… Best!\n",
      "Epoch  7/30 â”‚ Train: 0.2613, 88.4% â”‚ Val: 0.3048, 88.0% (no improve: 1)\n",
      "Epoch  8/30 â”‚ Train: 0.2499, 88.9% â”‚ Val: 0.2210, 89.3% âœ… Best!\n",
      "Epoch  9/30 â”‚ Train: 0.2470, 88.8% â”‚ Val: 0.2358, 87.3% (no improve: 1)\n",
      "Epoch 10/30 â”‚ Train: 0.2269, 89.6% â”‚ Val: 0.2017, 90.0% âœ… Best!\n",
      "Epoch 11/30 â”‚ Train: 0.2302, 89.6% â”‚ Val: 0.1920, 90.3% âœ… Best!\n",
      "Epoch 12/30 â”‚ Train: 0.2277, 89.6% â”‚ Val: 0.3115, 84.9% (no improve: 1)\n",
      "Epoch 13/30 â”‚ Train: 0.2102, 90.5% â”‚ Val: 0.2465, 86.5% (no improve: 2)\n",
      "Epoch 14/30 â”‚ Train: 0.2157, 90.2% â”‚ Val: 0.2221, 87.5% (no improve: 3)\n",
      "Epoch 15/30 â”‚ Train: 0.2052, 90.4% â”‚ Val: 0.2542, 85.5% (no improve: 4)\n",
      "Epoch 16/30 â”‚ Train: 0.2009, 90.5% â”‚ Val: 0.2470, 86.8% (no improve: 5)\n",
      "Epoch 17/30 â”‚ Train: 0.1980, 90.5% â”‚ Val: 0.3669, 82.3% (no improve: 6)\n",
      "Epoch 18/30 â”‚ Train: 0.1984, 90.8% â”‚ Val: 0.1966, 88.1% (no improve: 7)\n",
      "\n",
      "âš ï¸ Early stopping at epoch 18\n",
      "============================================================\n",
      "\n",
      "â±ï¸ í•™ìŠµ ì‹œê°„: 10.0ë¶„\n",
      "ğŸ† Best Val Accuracy: 90.35%\n"
     ]
    }
   ],
   "source": [
    "# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ\n",
    "print(\"\\nğŸš€ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...\")\n",
    "\n",
    "best_params = best_trial.params\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=FIXED_BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=FIXED_BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=FIXED_BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "model = ConveyorGuardModel(\n",
    "    embed_dim=best_params['embed_dim'],\n",
    "    num_heads=best_params['num_heads'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout'],\n",
    "    num_classes=4,\n",
    "    image_seq_len=IMAGE_FRAMES\n",
    ")\n",
    "\n",
    "# âš¡ DataParallel (T4 x2)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"âš¡ Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# AMP Scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=best_params['lr'],\n",
    "                              weight_decay=best_params['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "\n",
    "# í•™ìŠµ\n",
    "N_EPOCHS = 30\n",
    "PATIENCE = 7\n",
    "best_acc = 0\n",
    "no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(f\"\\ní•™ìŠµ ì‹œì‘ (Epochs: {N_EPOCHS}, Patience: {PATIENCE})\")\n",
    "print(f\"   Batch: {FIXED_BATCH_SIZE} (GPUë‹¹ {FIXED_BATCH_SIZE // max(torch.cuda.device_count(), 1)})\")\n",
    "print(f\"   DataParallel: {isinstance(model, nn.DataParallel)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_epoch_optimized(model, train_loader, criterion, optimizer, device, scaler)\n",
    "    val_loss, val_acc = evaluate_optimized(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{N_EPOCHS} â”‚ Train: {train_loss:.4f}, {train_acc:.1f}% â”‚ Val: {val_loss:.4f}, {val_acc:.1f}%\", end='')\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        no_improve = 0\n",
    "        # DataParallelì¸ ê²½ìš° model.module.state_dict() ì‚¬ìš©\n",
    "        model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n",
    "        best_model_state = model_to_save.state_dict().copy()\n",
    "        print(f\" âœ… Best!\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\" (no improve: {no_improve})\")\n",
    "    \n",
    "    if no_improve >= PATIENCE:\n",
    "        print(f\"\\nâš ï¸ Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nâ±ï¸ í•™ìŠµ ì‹œê°„: {total_time:.1f}ë¶„\")\n",
    "print(f\"ğŸ† Best Val Accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1. Ablation Study (ë©€í‹°ëª¨ë‹¬ íš¨ê³¼ ê²€ì¦)\n",
    "\n",
    "ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ê¸°ì—¬ë„ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•´ 4ê°€ì§€ êµ¬ì„±ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "| êµ¬ì„± | ì„¼ì„œ | ì´ë¯¸ì§€ | ì™¸ë¶€í™˜ê²½(FiLM) |\n",
    "|------|------|--------|---------------|\n",
    "| Sensor Only | âœ… | - | - |\n",
    "| Image Only | - | âœ… | - |\n",
    "| Sensor + Image | âœ… | âœ… | - |\n",
    "| Full (+ FiLM) | âœ… | âœ… | âœ… |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:13:31.430546Z",
     "iopub.status.busy": "2026-02-01T08:13:31.430263Z",
     "iopub.status.idle": "2026-02-01T08:13:31.443534Z",
     "shell.execute_reply": "2026-02-01T08:13:31.442833Z",
     "shell.execute_reply.started": "2026-02-01T08:13:31.430506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ablation ëª¨ë¸ ì •ì˜ ì™„ë£Œ (SensorOnly, ImageOnly, SensorImage)\n"
     ]
    }
   ],
   "source": [
    "# Ablation ëª¨ë¸ ì •ì˜\n",
    "\n",
    "class SensorOnlyModel(nn.Module):\n",
    "    \"\"\"ì„¼ì„œë§Œ ì‚¬ìš© (ì´ë¯¸ì§€ X, ì™¸ë¶€í™˜ê²½ X)\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=4, num_layers=2, dropout=0.1, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.sensor_encoder = SensorEncoder(input_dim=8, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.temporal = TemporalEncoder(embed_dim=embed_dim, num_heads=num_heads,\n",
    "                                        num_layers=num_layers, dropout=dropout, seq_len=30)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.LayerNorm(embed_dim),\n",
    "            nn.GELU(), nn.Dropout(dropout), nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sensors, images=None, externals=None):\n",
    "        x = self.sensor_encoder(sensors)\n",
    "        x = self.temporal(x)\n",
    "        return self.classifier(x.mean(dim=1))\n",
    "\n",
    "\n",
    "class ImageOnlyModel(nn.Module):\n",
    "    \"\"\"ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (ì„¼ì„œ X, ì™¸ë¶€í™˜ê²½ X)\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=4, num_layers=2, dropout=0.1, \n",
    "                 num_classes=4, image_seq_len=10):\n",
    "        super().__init__()\n",
    "        self.image_encoder = ImageEncoder(embed_dim=embed_dim, dropout=dropout)\n",
    "        self.temporal = TemporalEncoder(embed_dim=embed_dim, num_heads=num_heads,\n",
    "                                        num_layers=num_layers, dropout=dropout, seq_len=image_seq_len)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.LayerNorm(embed_dim),\n",
    "            nn.GELU(), nn.Dropout(dropout), nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sensors=None, images=None, externals=None):\n",
    "        x = self.image_encoder(images)\n",
    "        x = self.temporal(x)\n",
    "        return self.classifier(x.mean(dim=1))\n",
    "\n",
    "\n",
    "class SensorImageModel(nn.Module):\n",
    "    \"\"\"ì„¼ì„œ+ì´ë¯¸ì§€ (FiLM ì—†ìŒ)\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=4, num_layers=2, dropout=0.1, \n",
    "                 num_classes=4, image_seq_len=10):\n",
    "        super().__init__()\n",
    "        self.sensor_encoder = SensorEncoder(input_dim=8, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.image_encoder = ImageEncoder(embed_dim=embed_dim, dropout=dropout)\n",
    "        self.sensor_temporal = TemporalEncoder(embed_dim=embed_dim, num_heads=num_heads,\n",
    "                                                num_layers=num_layers, dropout=dropout, seq_len=30)\n",
    "        self.image_temporal = TemporalEncoder(embed_dim=embed_dim, num_heads=num_heads,\n",
    "                                               num_layers=num_layers, dropout=dropout, seq_len=image_seq_len)\n",
    "        self.fusion = CrossAttentionFusion(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim), nn.LayerNorm(embed_dim),\n",
    "            nn.GELU(), nn.Dropout(dropout), nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sensors, images, externals=None):\n",
    "        sensor_feat = self.sensor_encoder(sensors)\n",
    "        image_feat = self.image_encoder(images)\n",
    "        sensor_feat = self.sensor_temporal(sensor_feat)\n",
    "        image_feat = self.image_temporal(image_feat)\n",
    "        fused = self.fusion(sensor_feat, image_feat)\n",
    "        return self.classifier(fused.mean(dim=1))\n",
    "\n",
    "print(\"âœ… Ablation ëª¨ë¸ ì •ì˜ ì™„ë£Œ (SensorOnly, ImageOnly, SensorImage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:13:31.444731Z",
     "iopub.status.busy": "2026-02-01T08:13:31.444484Z",
     "iopub.status.idle": "2026-02-01T08:16:50.654602Z",
     "shell.execute_reply": "2026-02-01T08:16:50.653949Z",
     "shell.execute_reply.started": "2026-02-01T08:13:31.444710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³¸ ëª¨ë¸ GPU ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ\n",
      "\n",
      "ğŸ”¬ Ablation Study ì‹œì‘...\n",
      "============================================================\n",
      "\n",
      "â–¶ Sensor Only\n",
      "   Best Val Acc: 89.12%\n",
      "\n",
      "â–¶ Image Only\n",
      "   Best Val Acc: 69.56%\n",
      "\n",
      "â–¶ Sensor + Image\n",
      "   Best Val Acc: 89.64%\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Ablation Study ê²°ê³¼:\n",
      "============================================================\n",
      "   Sensor Only                    â†’ 89.12%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   Image Only                     â†’ 69.56%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   Sensor + Image                 â†’ 89.64%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   Sensor + Image + FiLM (Full)   â†’ 90.35%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ë³¸ ëª¨ë¸ GPU ë©”ëª¨ë¦¬ í•´ì œ (Ablationìš© ê³µê°„ í™•ë³´)\n",
    "del model, optimizer, scheduler, criterion, scaler\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"âœ… ë³¸ ëª¨ë¸ GPU ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ\")\n",
    "\n",
    "# Ablation í•™ìŠµ ë£¨í”„\n",
    "print(\"\\nğŸ”¬ Ablation Study ì‹œì‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ABLATION_EPOCHS = 10\n",
    "ABLATION_PATIENCE = 3\n",
    "\n",
    "ablation_configs = [\n",
    "    ('Sensor Only', SensorOnlyModel, {'embed_dim': best_params['embed_dim'],\n",
    "        'num_heads': best_params['num_heads'], 'num_layers': best_params['num_layers'],\n",
    "        'dropout': best_params['dropout']}),\n",
    "    ('Image Only', ImageOnlyModel, {'embed_dim': best_params['embed_dim'],\n",
    "        'num_heads': best_params['num_heads'], 'num_layers': best_params['num_layers'],\n",
    "        'dropout': best_params['dropout'], 'image_seq_len': IMAGE_FRAMES}),\n",
    "    ('Sensor + Image', SensorImageModel, {'embed_dim': best_params['embed_dim'],\n",
    "        'num_heads': best_params['num_heads'], 'num_layers': best_params['num_layers'],\n",
    "        'dropout': best_params['dropout'], 'image_seq_len': IMAGE_FRAMES}),\n",
    "]\n",
    "\n",
    "ablation_results = {}\n",
    "\n",
    "for name, ModelClass, kwargs in ablation_configs:\n",
    "    print(f\"\\nâ–¶ {name}\")\n",
    "    \n",
    "    abl_model = ModelClass(**kwargs).to(device)\n",
    "    abl_scaler = GradScaler()\n",
    "    abl_optimizer = torch.optim.AdamW(abl_model.parameters(), lr=best_params['lr'],\n",
    "                                       weight_decay=best_params['weight_decay'])\n",
    "    abl_criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "    \n",
    "    abl_best_acc = 0\n",
    "    abl_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, ABLATION_EPOCHS + 1):\n",
    "        train_loss, train_acc = train_epoch_optimized(\n",
    "            abl_model, train_loader, abl_criterion, abl_optimizer, device, abl_scaler)\n",
    "        val_loss, val_acc = evaluate_optimized(\n",
    "            abl_model, val_loader, abl_criterion, device)\n",
    "        \n",
    "        if val_acc > abl_best_acc:\n",
    "            abl_best_acc = val_acc\n",
    "            abl_no_improve = 0\n",
    "        else:\n",
    "            abl_no_improve += 1\n",
    "            if abl_no_improve >= ABLATION_PATIENCE:\n",
    "                break\n",
    "    \n",
    "    ablation_results[name] = abl_best_acc\n",
    "    print(f\"   Best Val Acc: {abl_best_acc:.2f}%\")\n",
    "    \n",
    "    del abl_model, abl_scaler, abl_optimizer, abl_criterion\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Full ëª¨ë¸ ê²°ê³¼ ì¶”ê°€\n",
    "ablation_results['Sensor + Image + FiLM (Full)'] = best_acc\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Ablation Study ê²°ê³¼:\")\n",
    "print(\"=\"*60)\n",
    "for name, acc in ablation_results.items():\n",
    "    bar = \"â–ˆ\" * int(acc / 2)\n",
    "    print(f\"   {name:30s} â†’ {acc:.2f}%  {bar}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:16:50.657349Z",
     "iopub.status.busy": "2026-02-01T08:16:50.656799Z",
     "iopub.status.idle": "2026-02-01T08:16:52.997985Z",
     "shell.execute_reply": "2026-02-01T08:16:52.996992Z",
     "shell.execute_reply.started": "2026-02-01T08:16:50.657327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Test Accuracy: 87.75%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ì •ìƒ       0.97      0.85      0.90       788\n",
      "          ê²½ë¯¸       0.70      0.91      0.79       371\n",
      "          ì¤‘ê°„       0.95      0.90      0.92       361\n",
      "          ì‹¬ê°       0.87      0.97      0.91        88\n",
      "\n",
      "    accuracy                           0.88      1608\n",
      "   macro avg       0.87      0.90      0.88      1608\n",
      "weighted avg       0.90      0.88      0.88      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best ëª¨ë¸ ì¬ìƒì„± + ë¡œë“œ (Ablationì—ì„œ ë©”ëª¨ë¦¬ í•´ì œí–ˆìœ¼ë¯€ë¡œ ìƒˆë¡œ ìƒì„±)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = ConveyorGuardModel(\n",
    "    embed_dim=best_params['embed_dim'],\n",
    "    num_heads=best_params['num_heads'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout'],\n",
    "    num_classes=4,\n",
    "    image_seq_len=IMAGE_FRAMES\n",
    ").to(device)\n",
    "model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "\n",
    "# Test í‰ê°€\n",
    "test_loss, test_acc = evaluate_optimized(model, test_loader, criterion, device)\n",
    "\n",
    "# Classification Report\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        sensors = batch['sensors'].to(device, non_blocking=True)\n",
    "        images = batch['images'].to(device, non_blocking=True)\n",
    "        externals = batch['externals'].to(device, non_blocking=True)\n",
    "        labels = batch['label'].to(device, non_blocking=True)\n",
    "        with autocast():\n",
    "            logits = model(sensors, images, externals)\n",
    "        all_preds.extend(logits.argmax(1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "label_names = ['ì •ìƒ', 'ê²½ë¯¸', 'ì¤‘ê°„', 'ì‹¬ê°']\n",
    "print(f\"\\nğŸ¯ Test Accuracy: {test_acc:.2f}%\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:16:53.000472Z",
     "iopub.status.busy": "2026-02-01T08:16:52.999962Z",
     "iopub.status.idle": "2026-02-01T08:16:55.590910Z",
     "shell.execute_reply": "2026-02-01T08:16:55.590125Z",
     "shell.execute_reply.started": "2026-02-01T08:16:53.000404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"620px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š tuned_confusion_matrix.html ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_text = [[str(y) for y in x] for x in cm]\n",
    "\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    cm,\n",
    "    x=label_names,\n",
    "    y=label_names,\n",
    "    annotation_text=cm_text,\n",
    "    colorscale='Blues',\n",
    "    showscale=True\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Confusion Matrix (Test Acc: {test_acc:.2f}%)',\n",
    "    xaxis_title='Predicted',\n",
    "    yaxis_title='Actual',\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show(renderer='iframe')\n",
    "fig.write_html(OUTPUT_DIR / 'tuned_confusion_matrix.html')\n",
    "print(f\"\\nğŸ“Š tuned_confusion_matrix.html ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ëª¨ë¸ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:16:55.592731Z",
     "iopub.status.busy": "2026-02-01T08:16:55.592190Z",
     "iopub.status.idle": "2026-02-01T08:16:55.641278Z",
     "shell.execute_reply": "2026-02-01T08:16:55.640542Z",
     "shell.execute_reply.started": "2026-02-01T08:16:55.592708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: /kaggle/working/tuned_model.pt\n",
      "   Best Val Acc: 90.35%\n",
      "   Test Acc: 87.75%\n",
      "   Ablation ê²°ê³¼ í¬í•¨: ['Sensor Only', 'Image Only', 'Sensor + Image', 'Sensor + Image + FiLM (Full)']\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì €ì¥\n",
    "best_model_path = OUTPUT_DIR / 'tuned_model.pt'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'best_val_acc': best_acc,\n",
    "    'test_acc': test_acc,\n",
    "    'best_params': best_params,\n",
    "    'ablation_results': ablation_results,\n",
    "    'model_config': {\n",
    "        'embed_dim': best_params['embed_dim'],\n",
    "        'num_heads': best_params['num_heads'],\n",
    "        'num_layers': best_params['num_layers'],\n",
    "        'dropout': best_params['dropout'],\n",
    "        'num_classes': 4,\n",
    "        'sensor_seq_len': 30,\n",
    "        'image_seq_len': IMAGE_FRAMES\n",
    "    }\n",
    "}, best_model_path)\n",
    "\n",
    "# Optuna Study ì €ì¥\n",
    "import pickle\n",
    "with open(OUTPUT_DIR / 'optuna_study.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {best_model_path}\")\n",
    "print(f\"   Best Val Acc: {best_acc:.2f}%\")\n",
    "print(f\"   Test Acc: {test_acc:.2f}%\")\n",
    "print(f\"   Ablation ê²°ê³¼ í¬í•¨: {list(ablation_results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle ë°ì´í„°ì…‹ ì—…ë¡œë“œ (API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:16:55.642540Z",
     "iopub.status.busy": "2026-02-01T08:16:55.642258Z",
     "iopub.status.idle": "2026-02-01T08:17:00.997283Z",
     "shell.execute_reply": "2026-02-01T08:17:00.996365Z",
     "shell.execute_reply.started": "2026-02-01T08:16:55.642507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file optuna_study.pkl\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.6k/15.6k [00:00<00:00, 39.1kB/s]\n",
      "Upload successful: optuna_study.pkl (16KB)\n",
      "Starting upload for file tuned_model.pt\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.5M/16.5M [00:00<00:00, 29.9MB/s]\n",
      "Upload successful: tuned_model.pt (16MB)\n",
      "Starting upload for file tuned_confusion_matrix.html\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.36M/4.36M [00:00<00:00, 9.49MB/s]\n",
      "Upload successful: tuned_confusion_matrix.html (4MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/kukass/conveyorguard-tuned\n",
      "\n",
      "âœ… conveyorguard-tuned ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì™„ë£Œ!\n",
      "   â†’ 06_ensemble, 07_final_comparisonì—ì„œ ì‚¬ìš© ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = 'kukass'\n",
    "os.environ['KAGGLE_KEY'] = 'KGAT_c973fff8eb3e1ccb19f3e9d683eb17dc'\n",
    "\n",
    "UPLOAD_DIR = '/kaggle/working/dataset_upload'\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "output_files = ['tuned_model.pt', 'optuna_study.pkl', 'tuned_confusion_matrix.html']\n",
    "for f in output_files:\n",
    "    src = f'/kaggle/working/{f}'\n",
    "    dst = f'{UPLOAD_DIR}/{f}'\n",
    "    if os.path.exists(src) and not os.path.exists(dst):\n",
    "        os.symlink(src, dst)\n",
    "\n",
    "meta = {\n",
    "    \"title\": \"conveyorguard-tuned\",\n",
    "    \"id\": \"kukass/conveyorguard-tuned\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "}\n",
    "with open(f'{UPLOAD_DIR}/dataset-metadata.json', 'w') as f:\n",
    "    json.dump(meta, f)\n",
    "\n",
    "!kaggle datasets create -p {UPLOAD_DIR} --dir-mode zip\n",
    "\n",
    "print(\"\\nâœ… conveyorguard-tuned ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"   â†’ 06_ensemble, 07_final_comparisonì—ì„œ ì‚¬ìš© ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "| í•­ëª© | Baseline (02) | Tuned (04) |\n",
    "|------|---------------|------------|\n",
    "| Accelerator | GPU T4 x2 | GPU T4 x2 |\n",
    "| ìµœì í™” | ìˆ˜ë™ | Optuna |\n",
    "| DataParallel | âœ… | âœ… |\n",
    "| AMP | âœ… | âœ… |\n",
    "| FiLM | âœ… | âœ… |\n",
    "\n",
    "### ğŸ”¬ Ablation Study\n",
    "```\n",
    "Sensor Only           â†’ ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° í•œê³„ í™•ì¸\n",
    "Image Only            â†’ ì—´í™”ìƒë§Œìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„\n",
    "Sensor + Image        â†’ ë©€í‹°ëª¨ë‹¬ ìœµí•© íš¨ê³¼\n",
    "Sensor + Image + FiLM â†’ ì™¸ë¶€í™˜ê²½ ì¡°ê±´í™”ë¡œ ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ\n",
    "```\n",
    "\n",
    "### âš¡ GPU T4 x2 ìµœì í™”\n",
    "```\n",
    "- DataParallel: 2x GPU ë³‘ë ¬ ì²˜ë¦¬\n",
    "- AMP (Mixed Precision): ë©”ëª¨ë¦¬ ì ˆê° + ì†ë„ í–¥ìƒ\n",
    "- cuDNN benchmark: ìµœì  ì»¤ë„ ìë™ ì„ íƒ\n",
    "- ì´ë¯¸ì§€ ì„œë¸Œìƒ˜í”Œë§: 30 â†’ 10 í”„ë ˆì„\n",
    "- Optuna Pruning: ë¹„íš¨ìœ¨ Trial ì¡°ê¸° ì¢…ë£Œ\n",
    "```\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "- `05_llm_comparison.ipynb`: LLM ì§„ë‹¨ ë¹„êµ + LangGraph ë©€í‹° ì—ì´ì „íŠ¸"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9381506,
     "sourceId": 14685395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
