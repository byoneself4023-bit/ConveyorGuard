# ConveyorGuard 최종 비교 및 결론

## 1. 목표

> **전체 파이프라인(00~06) 결과를 종합 비교하고 프로덕션 모델 선택**

### 핵심 질문
- 13개 모델 중 최고 성능은?
- 프로덕션에 적합한 모델은?
- 멀티모달 DL과 ML의 차이는 왜 발생했는가?

---

## 2. 전체 모델 성능 순위

| 순위 | 모델 | 유형 | Test Acc | Test F1 | Train Time |
|------|------|------|----------|---------|------------|
| 🥇 | Stacking | Ensemble | 96.89% | 96.89% | - |
| 🥇 | LightGBM | ML | 96.89% | 96.43% | 2.7초 |
| 3 | Weighted Voting | Ensemble | 96.70% | 96.71% | - |
| 3 | XGBoost | ML | 96.70% | 96.28% | 3.8초 |
| 5 | Soft Voting | Ensemble | 96.64% | 96.64% | - |
| 6 | CatBoost | ML | 96.46% | 96.01% | 21.5초 |
| 7 | RandomForest | ML | 95.58% | 95.19% | 3.7초 |
| 8 | CNN+Transformer (Baseline) | DL | 93.24% | 92.80% | 36.3분 |
| 9 | DecisionTree | ML | 92.97% | 92.00% | 0.6초 |
| 10 | KNN (k=5) | ML | 89.12% | 88.28% | 0.0초 |
| 11 | SVM (RBF) | ML | 87.75% | 87.01% | 1.0초 |
| 11 | CNN+Transformer (Tuned) | DL | 87.75% | 88.13% | 10.0분 |
| 13 | LogisticRegression | ML | 87.31% | 86.81% | 2.0초 |

---

## 3. 유형별 분석

### ML vs DL vs Ensemble

| 유형 | Best 모델 | Test Acc | 특징 |
|------|-----------|----------|------|
| ML | LightGBM | **96.89%** | 빠르고 해석 가능 |
| DL | Baseline CNN | 93.24% | 멀티모달 직접 처리 |
| Ensemble | Stacking | 96.89% | ML+DL 결합 |

### ML이 DL보다 높은 이유

| 원인 | 설명 |
|------|------|
| 피처 엔지니어링 | 시계열 통계 피처 (mean, std, min, max 등) 가 핵심 정보 압축 |
| 데이터 규모 | 7,311개 → DL 학습에 불충분 |
| 정형 데이터 강점 | 센서 데이터는 ML에 유리 |

---

## 4. Ablation Study 결과

| 구성 | 센서 | 이미지 | FiLM | Val Acc |
|------|:----:|:------:|:----:|---------|
| Sensor Only | ✅ | - | - | 89.12% |
| Image Only | - | ✅ | - | 69.56% |
| Sensor + Image | ✅ | ✅ | - | 89.64% |
| **Full (+ FiLM)** | ✅ | ✅ | ✅ | **90.35%** |

### 멀티모달 효과

```
센서만 → 센서+이미지: +0.5%p (이미지 추가 효과)
이미지만 → 센서+이미지: +20.1%p (센서 추가 효과)
센서+이미지 → +FiLM: +0.7%p (외부환경 조건화 효과)
단일 최고 → Full: +1.2%p (멀티모달 총 효과)
```

**→ "왜 멀티모달인가?" 실험적으로 답변 완료!**

---

## 5. 앙상블 효과 분석

| 비교 | 결과 |
|------|------|
| LightGBM 단독 | 96.89% |
| Stacking | 96.89% (동일) |
| Weighted Voting | 96.70% (하락) |
| Soft Voting | 96.64% (하락) |

**결론: 앙상블 효과 없음**
- ML이 이미 충분히 높음
- DL이 ML과 다른 패턴을 보완하지 못함
- 앙상블이 항상 좋진 않다는 것을 실험적으로 확인

---

## 6. 다차원 비교 (Top 모델)

| 항목 | LightGBM (ML) | CNN+Transformer (DL) | Stacking (Ensemble) |
|------|---------------|----------------------|---------------------|
| Test Acc | 96.89% | 87.75% | 96.89% |
| Test F1 | 96.43% | 88.13% | 96.89% |
| 모델 크기 | 3.1 MB | 16.5 MB | 1 KB |
| 학습 속도 | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐ |
| 해석 가능성 | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| 멀티모달 | ❌ | ✅ | ❌ |
| 경량성 | ⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐⭐ |

---

## 7. LLM 진단 연동

### 시나리오

```
ML/DL 모델 → "심각" 판정
    ↓
Gemini 2.5 Flash → 센서 데이터 기반 진단 리포트 자동 생성
    ↓
이상 분석 + 원인 추정 + 조치 사항 + 위험도 평가
```

### 진단 리포트 예시 (심각 샘플)

| 항목 | 내용 |
|------|------|
| 이상 분석 | NTC 0.3°C (정상 40~60°C), CT 전류 0.0A (정상 20~40A) |
| 원인 추정 | 1. 전원 공급 문제 2. 핵심 부품 고장 3. 센서 오작동 |
| 즉시 조치 | 장비 가동 중단, 전원 확인, 전문 인력 투입 |
| 위험도 | **상 (High)** |

**→ ML 판정 + LLM 해석 = 완전한 예지보전 시스템**

---

## 8. 모델 선택 권고

### 프로덕션 배포 전략

```
Phase 1: LightGBM 단독 배포
  → 빠른 추론 (2.7초), SHAP 해석, 3.1MB 경량
  → 96.89% 정확도, 심각 Recall 98%

Phase 2: Ensemble 추가 (필요시)
  → Stacking으로 ML+DL 결합
  → 실질적 성능 향상은 없으나 안정성 확보

Phase 3: LLM 진단 연동
  → Gemini 2.5 Flash API로 자연어 진단 보고서
  → 05번 LangGraph 멀티 에이전트 활용
```

---

## 9. 전체 파이프라인 요약

```
00_EDA
  └── 클래스 불균형 발견 (심각 5.1%)
        ↓
01_preprocess
  └── 윈도우 생성 (30프레임, stride 10) + 세션 기반 Split
        ↓
02_baseline_cnn
  └── CNN+Transformer 3-modal → Test 92.72%
        ↓
03_ml_baseline
  └── ML 8종 비교 → LightGBM 96.89% 🏆
        ↓
04_dl_tuning
  ├── Optuna 최적화 → Test 87.75%
  ├── Ablation Study → 멀티모달 효과 입증
  └── GPU 최적화 (속도 3.6배 향상)
        ↓
05_llm_comparison
  ├── LLM 3종 비교 → Gemini 최고
  └── LangGraph 멀티 에이전트 → 자동 진단 리포트
        ↓
06_ensemble
  ├── Soft/Weighted/Stacking
  └── 앙상블 효과 없음 확인 (LightGBM과 동률)
        ↓
07_final_comparison (현재)
  ├── 13개 모델 종합 비교
  ├── LLM 진단 연동 데모
  └── 프로덕션 모델 선택 → LightGBM
```

---

## 핵심 요약

### 🏆 성능 순위

```
1. LightGBM / Stacking (동률) → 96.89%
   → LightGBM: 프로덕션 최적 (3.1MB, 빠르고 해석 가능)
   → Stacking: 앙상블 효과는 미미 (동일 성능)
2. XGBoost → 96.70%
3. CNN+Transformer (Baseline) → 92.72% (멀티모달 직접 처리)
4. CNN+Transformer (Tuned) → 87.75% (속도 최적화 trade-off)
```

### 🔬 Ablation Study

```
센서만 < 이미지만 < 센서+이미지 < 센서+이미지+FiLM
→ 멀티모달 융합이 단일 모달리티 대비 유의미한 성능 향상
→ 외부환경 조건화(FiLM)가 추가적 개선 제공
```

### 💡 핵심 교훈

| 항목 | 내용 |
|------|------|
| ML vs DL | 정형 데이터 + 피처 엔지니어링 → ML 우세 |
| 앙상블 | 만능 아님, 모델 다양성이 핵심 |
| 멀티모달 | Ablation으로 효과 입증 (+1.2%p) |
| LLM 연동 | ML 판정 + LLM 해석 = 완전한 예지보전 |
| 프로덕션 | LightGBM 단독이 최적 (간단 + 빠름 + 정확) |

### 🎯 ConveyorGuard 프로젝트 완료! ✅
